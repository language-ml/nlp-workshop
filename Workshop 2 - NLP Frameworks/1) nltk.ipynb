{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<img src='https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png' width=150 height=150> <br>\n",
    "<font color=0F5298 size=6>\n",
    "Natural Language Processing<br>\n",
    "<font color=2565AE size=4>\n",
    "Computer Engineering Department<br>\n",
    "Spring 2025<br>\n",
    "<font color=3C99D size=4>\n",
    "Workshop 1 - NLP Frameworks - NLTK<br>\n",
    "<font color=696880 size=3>\n",
    "<a href='https://language.ml'>https://language.ml</a><br>\n",
    "info [AT] language [dot] ml"
   ],
   "id": "56b7d277eb2ccb7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìñ Part 1: Introduction\n",
    "\n",
    "## ‚ùì What is NLTK? ([NLTK Official Website](https://www.nltk.org/))\n",
    "The Natural Language Toolkit (NLTK) is a popular Python library for working with human language data. It provides easy access to a wide range of text processing tools such as **tokenization**, **stemming**, **lemmatization**, **part-of-speech tagging**, and more. NLTK also includes various corpora and lexical resources to support NLP tasks.\n",
    "\n",
    "It‚Äôs often used for:\n",
    "- Teaching NLP concepts\n",
    "- Research prototyping\n",
    "- Basic language analysis tasks\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use NLTK\n",
    "- **Educational Purposes:** It is ideal for learning fundamental NLP concepts such as tokenization, POS tagging, parsing, etc., because of its transparent and modular design.\n",
    "- **Prototyping:** When you want to quickly try out an idea without needing large-scale data or high performance.\n",
    "- **Rule-Based NLP:** For projects that involve hand-crafted rules or custom tokenization.\n",
    "- **Working with Classical NLP Tasks:** Especially if you want to explore linguistic structure using treebanks, grammars, or symbolic approaches.\n",
    "- **Lightweight Projects:** If you don‚Äôt need deep learning models or large-scale pipelines, NLTK provides a rich set of tools out of the box.\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ NLTK is not recommended for:\n",
    "- **Large-scale production systems** (use spaCy or Hugging Face instead)\n",
    "- **Neural network-based NLP** (use PyTorch, TensorFlow, or Hugging Face Transformers)"
   ],
   "id": "2431cbc451d7f1ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ‚öôÔ∏è Installation & Setup",
   "id": "917c87d3c9299ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.330145Z",
     "start_time": "2025-04-23T18:25:44.945255Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install nltk",
   "id": "30bb53ba46c2000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk) (4.67.1)\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.337921Z",
     "start_time": "2025-04-23T18:25:45.335907Z"
    }
   },
   "cell_type": "code",
   "source": "import nltk",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚úÇÔ∏è Part 2: Basic Text Preprocessing\n",
    "\n",
    "Text preprocessing is the first and most important step in any NLP pipeline. It involves cleaning and structuring raw text into a format that can be used for further analysis or modeling."
   ],
   "id": "5aae6c5a367be086"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üì¶ Downloading Resources",
   "id": "21b78fab2b3127e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.349328Z",
     "start_time": "2025-04-23T18:25:45.346859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt_tab')  # For tokenization, NLTK 3.8.2 or newer\n",
    "nltk.download('punkt')  # For tokenization, NLTK 3.8.1 or older\n",
    "nltk.download('stopwords')  # For stopword removal\n",
    "nltk.download('wordnet')  # For stemming and lemmatization"
   ],
   "id": "730dc494e76a945",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 2.1 Tokenization\n",
    "Tokenization is the process of breaking down text into smaller units like **words** or **sentences**.\n",
    "\n",
    "**‚ö†Ô∏è Note: Persian is not natively supported by NLTK.**"
   ],
   "id": "4b988ae660a375ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ‚úÖ Sentence Tokenization",
   "id": "1b7c5a5a10cfd713"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.362686Z",
     "start_time": "2025-04-23T18:25:45.361004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"The children were playing in the garden. They had a great time.\"\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ],
   "id": "68b0b8c3216a761b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The children were playing in the garden.', 'They had a great time.']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ‚úÖ Word Tokenization",
   "id": "a6ed3a8d847c09a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.380535Z",
     "start_time": "2025-04-23T18:25:45.378622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ],
   "id": "a7ea85c564fd413",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'children', 'were', 'playing', 'in', 'the', 'garden', '.', 'They', 'had', 'a', 'great', 'time', '.']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 2.2 Stopword Removal",
   "id": "c47efb901b863fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.399434Z",
     "start_time": "2025-04-23T18:25:45.397144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "removed = [word for word in words if word.lower() in stop_words]\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print('Removed stopwords:', removed)\n",
    "print('Filtered words:', filtered_words)"
   ],
   "id": "55db7d754cf6bf7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed stopwords: ['The', 'were', 'in', 'the', 'They', 'had', 'a']\n",
      "Filtered words: ['children', 'playing', 'garden', '.', 'great', 'time', '.']\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 2.3 Stemming",
   "id": "fd8bedfa0ef17968"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.411012Z",
     "start_time": "2025-04-23T18:25:45.409230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "print(stemmed_words)"
   ],
   "id": "478435de19cf2cc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['children', 'play', 'garden', '.', 'great', 'time', '.']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 2.4 Lemmatization",
   "id": "6f2d7a87fe7d165f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.429448Z",
     "start_time": "2025-04-23T18:25:45.427497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(lemmatized_words)"
   ],
   "id": "46ea965a6c4d0f50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['child', 'playing', 'garden', '.', 'great', 'time', '.']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß© Part 3: POS Tagging (Part-of-Speech Tagging)\n",
    "\n",
    "**POS Tagging** is the process of labeling each word in a sentence with its corresponding part of speech, such as **noun**, **verb**, **adjective**, etc.\n",
    "\n",
    "This helps in understanding the **grammatical structure** of a sentence and is used in many NLP tasks like **parsing**, **named entity recognition**, and **question answering**."
   ],
   "id": "df111312ae436ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üì¶ Downloading Resources",
   "id": "109f454f9f3e9b76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.447824Z",
     "start_time": "2025-04-23T18:25:45.445650Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('averaged_perceptron_tagger_eng')  # POS tagger model",
   "id": "c51dea9252b1bfad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 3.1 Basic POS Tagging",
   "id": "20dece9d48c696a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.464892Z",
     "start_time": "2025-04-23T18:25:45.462427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "text = 'In October 2024, Dr. Emily Smith of MIT and Professor Brian Lee from Stanford University visited the Googleplex in Mountain View, California to present their NLP research at the ACL workshop.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "print('Tagged:', tagged)"
   ],
   "id": "fd298afcf92f7799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged: [('In', 'IN'), ('October', 'NNP'), ('2024', 'CD'), (',', ','), ('Dr.', 'NNP'), ('Emily', 'NNP'), ('Smith', 'NNP'), ('of', 'IN'), ('MIT', 'NNP'), ('and', 'CC'), ('Professor', 'NNP'), ('Brian', 'NNP'), ('Lee', 'NNP'), ('from', 'IN'), ('Stanford', 'NNP'), ('University', 'NNP'), ('visited', 'VBD'), ('the', 'DT'), ('Googleplex', 'NNP'), ('in', 'IN'), ('Mountain', 'NNP'), ('View', 'NNP'), (',', ','), ('California', 'NNP'), ('to', 'TO'), ('present', 'VB'), ('their', 'PRP$'), ('NLP', 'NNP'), ('research', 'NN'), ('at', 'IN'), ('the', 'DT'), ('ACL', 'NNP'), ('workshop', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 3.2 POS Tag Explanation\n",
    "\n",
    "The tags returned by `pos_tag()` follow the **Penn Treebank** tag set. Here are a few common ones:\n",
    "\n",
    "| Tag | Meaning            | Example       |\n",
    "|-----|---------------------|---------------|\n",
    "| NN  | Noun, singular      | cat, car      |\n",
    "| NNS | Noun, plural        | cats, cars    |\n",
    "| VB  | Verb, base form     | run           |\n",
    "| VBD | Verb, past tense    | ran           |\n",
    "| JJ  | Adjective           | happy         |\n",
    "| RB  | Adverb              | quickly       |\n",
    "| IN  | Preposition         | in, on        |\n",
    "| DT  | Determiner          | the, a        |\n",
    "| PRP | Personal pronoun    | he, she, it   |"
   ],
   "id": "bae4e16776f43e8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.489761Z",
     "start_time": "2025-04-23T18:25:45.487669Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('tagsets_json')",
   "id": "d57309e0b52545b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets_json to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package tagsets_json is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.508663Z",
     "start_time": "2025-04-23T18:25:45.506735Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.help.upenn_tagset('NNP')",
   "id": "9c32cf45da9b38a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.525388Z",
     "start_time": "2025-04-23T18:25:45.523275Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.help.upenn_tagset('DT')",
   "id": "9e82ca6ee2259581",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üßæ Part 4: Named Entity Recognition (NER)\n",
    "\n",
    "**Named Entity Recognition (NER)** is the process of identifying and classifying named entities in text into predefined categories such as **person names**, **organizations**, **locations**, **dates**, etc."
   ],
   "id": "646e96958e03e21a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üì¶ Downloading Resources",
   "id": "6d2c30102c2ba245"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:45.541217Z",
     "start_time": "2025-04-23T18:25:45.539036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('maxent_ne_chunker_tab')  # NER chunker\n",
    "nltk.download('words')  # Required for NE chunking"
   ],
   "id": "5c567cacdc4cdcda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 4.1 Basic NER with `ne_chunk()`",
   "id": "33d9ddde97144d1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:46.568407Z",
     "start_time": "2025-04-23T18:25:45.610071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "text = 'In October 2024, Dr. Emily Smith of MIT and Professor Brian Lee from Stanford University visited the Googleplex in Mountain View, California to present their NLP research at the ACL workshop.'\n",
    "\n",
    "# Tokenize, tag, and chunk\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "named_entities = ne_chunk(tags)\n",
    "\n",
    "print(named_entities)"
   ],
   "id": "8af8eaebdc05e011",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  In/IN\n",
      "  October/NNP\n",
      "  2024/CD\n",
      "  ,/,\n",
      "  Dr./NNP\n",
      "  (PERSON Emily/NNP Smith/NNP)\n",
      "  of/IN\n",
      "  (ORGANIZATION MIT/NNP)\n",
      "  and/CC\n",
      "  (ORGANIZATION Professor/NNP Brian/NNP Lee/NNP)\n",
      "  from/IN\n",
      "  (ORGANIZATION Stanford/NNP University/NNP)\n",
      "  visited/VBD\n",
      "  the/DT\n",
      "  (ORGANIZATION Googleplex/NNP)\n",
      "  in/IN\n",
      "  (GPE Mountain/NNP View/NNP)\n",
      "  ,/,\n",
      "  (GPE California/NNP)\n",
      "  to/TO\n",
      "  present/VB\n",
      "  their/PRP$\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  research/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION ACL/NNP)\n",
      "  workshop/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> üìå Note: The `ne_chunk` function doesn't always recognize dates and money values perfectly. For high accuracy, deep-learning-based NER tools like spaCy or Hugging Face are preferred ‚Äî and you'll cover them later in the workshop.",
   "id": "4a9a7d40ba4f71c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 4.2 Display Named Entities in a More Readable Way\n",
    "\n",
    "You can extract only the named entities and display them clearly:"
   ],
   "id": "32cb3b82224b9a20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:46.575544Z",
     "start_time": "2025-04-23T18:25:46.573334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tree import Tree\n",
    "\n",
    "\n",
    "def extract_named_entities(chunked_tree):\n",
    "    named_entities = []\n",
    "\n",
    "    for subtree in chunked_tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            entity = ' '.join([token for token, tag in subtree.leaves()])\n",
    "            entity_type = subtree.label()\n",
    "            named_entities.append((entity, entity_type))\n",
    "\n",
    "    return named_entities\n",
    "\n",
    "\n",
    "entities = extract_named_entities(named_entities)\n",
    "print('Named Entities:', entities)"
   ],
   "id": "8f6d91663916dc2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Emily Smith', 'PERSON'), ('MIT', 'ORGANIZATION'), ('Professor Brian Lee', 'ORGANIZATION'), ('Stanford University', 'ORGANIZATION'), ('Googleplex', 'ORGANIZATION'), ('Mountain View', 'GPE'), ('California', 'GPE'), ('NLP', 'ORGANIZATION'), ('ACL', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 4.3 Common Named Entity Types\n",
    "\n",
    "The table below summarizes the most common named entity labels used by NLTK‚Äôs ne_chunk() function (based on the Penn Treebank and CoNLL tagsets):\n",
    "\n",
    "| Label            | Meaning                                          |\n",
    "|------------------|--------------------------------------------------|\n",
    "| **PERSON**       | Individual people                                |\n",
    "| **ORGANIZATION** | Companies, institutions, agencies                |\n",
    "| **GPE**          | Geopolitical entities: countries, cities, states |\n",
    "| **FACILITY**     | Physical facilities: buildings, airports, labs   |\n",
    "| **LOCATION**     | Natural locations: rivers, mountains, regions    |"
   ],
   "id": "24a6966a1f07515d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üóÇÔ∏è Part 5: Text Classification (Optional)\n",
    "\n",
    "Text classification is the task of assigning a category or label to a given piece of text. Examples include:\n",
    "- Spam detection\n",
    "- Sentiment analysis\n",
    "- News categorization\n",
    "\n",
    "NLTK offers tools for training basic classifiers using classical machine learning (not deep learning)."
   ],
   "id": "121eb8c4415f80ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üì¶ Downloading Resources",
   "id": "80920438cd4c2173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:49.563545Z",
     "start_time": "2025-04-23T18:25:46.593506Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('movie_reviews')  # Sample dataset",
   "id": "528c3b60248830e2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/AmirMohammad/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 5.1 Load the Dataset\n",
    "\n",
    "We‚Äôll use the movie reviews corpus included in NLTK. It contains 1000 positive and negative reviews labeled accordingly."
   ],
   "id": "b39f153311398cee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:49.569871Z",
     "start_time": "2025-04-23T18:25:49.568473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import random"
   ],
   "id": "c548c70f2c2aab4f",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:49.586637Z",
     "start_time": "2025-04-23T18:25:49.585047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ],
   "id": "d5377ddf99875e5d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:49.595751Z",
     "start_time": "2025-04-23T18:25:49.592710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Categories:', movie_reviews.categories())\n",
    "print('Number of reviews:', len(movie_reviews.fileids()))\n",
    "\n",
    "print('Positive reviews:', len(movie_reviews.fileids('pos')))\n",
    "print('Negative reviews:', len(movie_reviews.fileids('neg')))"
   ],
   "id": "70e18760707166f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['neg', 'pos']\n",
      "Number of reviews: 2000\n",
      "Positive reviews: 1000\n",
      "Negative reviews: 1000\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:50.253905Z",
     "start_time": "2025-04-23T18:25:49.604195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create list of (words, category) pairs\n",
    "documents = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((list(movie_reviews.words(fileid)), category))\n",
    "\n",
    "# Shuffle documents for randomness\n",
    "random.shuffle(documents)"
   ],
   "id": "9266e9e6e54e0761",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:50.260886Z",
     "start_time": "2025-04-23T18:25:50.259220Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0])",
   "id": "c9a36f49bb5cfe77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['mr', '.', 'bean', ',', 'a', 'bumbling', 'security', 'guard', 'from', 'england', 'is', 'sent', 'to', 'la', 'to', 'help', 'with', 'the', 'grandiose', 'homecoming', 'of', 'a', 'masterpiece', 'american', 'painting', '.', 'the', 'first', 'two', 'words', 'should', 'have', 'said', 'enough', 'to', 'let', 'you', 'know', 'what', 'occurs', 'during', 'bean', \"'\", 's', 'trip', 'to', 'la', ',', 'but', 'if', 'they', 'didn', \"'\", 't', 'look', 'out', 'because', 'you', 'are', 'in', 'for', 'a', 'rather', 'interesting', 'if', 'not', 'odd', 'ride', '.', 'heck', 'depending', 'on', 'your', 'humor', 'you', 'might', 'end', 'up', 'laughing', 'through', 'the', 'whole', 'flick', '.', 'either', 'way', 'look', 'out', 'america', 'bean', 'is', 'coming', '.', 'well', ',', 'what', 'can', 'really', 'be', 'said', 'about', 'this', 'movie', ',', 'there', 'is', 'very', 'little', 'discernible', 'plot', '.', 'that', 'much', 'is', 'not', 'hard', 'to', 'grapple', 'with', 'for', 'it', 'is', 'a', 'slapstick', 'comedy', '.', 'it', 'achieves', 'that', 'goal', 'rather', 'admirably', ',', 'but', 'because', 'it', 'is', 'that', ',', 'the', 'plot', 'is', 'just', 'screaming', 'for', 'help', '.', 'the', 'whole', 'premise', 'that', 'the', 'movie', 'is', 'based', 'on', 'is', 'to', 'say', 'the', 'least', 'flawed', '.', 'the', 'movie', 'had', 'its', 'funny', 'moments', 'but', 'there', 'was', 'no', 'real', 'story', 'line', 'other', 'than', 'something', 'that', 'could', 'be', 'thought', 'up', 'on', 'a', 'whim', 'and', 'carried', 'through', 'and', 'in', 'many', 'causes', 'ad', '-', 'libbed', 'as', 'you', 'went', '.', 'don', \"'\", 't', 'go', 'into', 'this', 'movie', 'expecting', 'and', 'theatrical', 'masterpiece', '.', 'but', 'if', 'this', 'form', 'of', 'humor', 'floats', 'your', 'boat', 'then', 'you', 'will', 'truly', 'enjoy', 'this', 'movie', ',', 'even', 'if', 'you', 'don', \"'\", 't', 'like', 'slapstick', 'style', 'humor', 'you', 'will', 'end', 'up', 'laughing', 'because', 'something', \"'\", 's', 'are', 'just', 'so', 'stupid', '.', 'the', 'movie', 'goes', 'out', 'and', 'accomplishes', 'what', 'it', 'aims', ',', 'or', 'so', 'it', 'seems', '.', 'now', 'when', 'you', 'look', 'at', 'the', 'acting', 'in', 'this', 'movie', 'you', 'have', 'to', 'think', 'about', 'two', 'things', ',', 'first', 'was', 'there', 'any', 'real', 'acting', 'and', 'how', 'hard', 'is', 'it', 'to', 'act', 'in', 'the', 'slapstick', 'manner', '.', 'well', ',', 'there', 'was', 'no', 'real', 'acting', 'in', 'this', 'movie', 'but', 'some', 'of', 'the', 'slapstick', 'wasn', \"'\", 't', 'the', 'easiest', 'i', 'am', 'sure', '.', 'i', 'have', 'to', 'concede', 'that', 'mr', '.', 'atkinson', \"'\", 's', 'acting', 'in', 'this', 'movie', 'is', 'well', 'done', '.', 'although', 'the', 'role', 'isn', \"'\", 't', 'too', 'demanding', 'the', 'slapstick', 'is', '.', 'i', 'think', 'that', 'the', 'character', 'could', 'have', 'had', 'a', 'bit', 'more', 'dialogue', ',', 'it', 'would', 'have', 'added', 'quite', 'a', 'bit', 'to', 'the', 'overall', 'effect', 'of', 'the', 'movie', '.', 'now', 'the', 'rest', 'of', 'the', 'actors', 'in', 'the', 'movie', ',', 'bad', 'acting', 'and', 'poor', 'casting', '.', 'i', 'think', 'that', 'the', 'role', 'opposite', 'bean', 'could', 'have', 'been', 'better', ',', 'just', 'seemed', 'wrong', 'for', 'the', 'movie', '.', 'a', 'different', 'actor', 'might', 'have', 'done', 'a', 'better', 'job', 'of', 'it', 'but', 'i', 'wont', 'presume', 'that', 'wasn', \"'\", 't', 'what', 'was', 'trying', 'to', 'be', 'achieved', '.', 'one', 'thing', 'that', 'i', 'must', 'say', ',', 'simply', 'to', 'get', 'if', 'off', 'my', 'chest', 'is', 'that', 'i', 'think', 'transferring', 'a', 'sitcom', 'to', 'tv', 'usually', 'produces', 'rather', 'disastrous', 'results', '.', 'tv', 'shows', 'should', 'do', 'just', 'that', 'stay', 'on', 'tv', ',', 'it', 'will', 'probably', 'save', 'some', 'producers', 'from', 'getting', 'ulcers', '.', 'i', 'can', 'only', 'think', 'of', 'a', 'couple', 'examples', 'of', 'tv', 'going', 'to', 'the', 'big', 'screen', 'effectively', ',', 'the', 'best', 'known', 'of', 'those', 'would', 'have', 'to', 'be', 'star', 'trek', '.', 'bean', 'seriously', 'fails', 'to', 'accomplish', 'anything', 'close', 'to', 'what', 'that', 'series', 'gone', 'movie', 'achieved', '.', 'now', 'another', 'thing', 'that', 'i', 'have', 'to', 'state', 'again', 'is', 'this', 'movie', 'has', 'narrowed', 'its', 'target', 'audience', 'fairly', 'tightly', '.', 'the', 'form', 'of', 'humor', 'in', 'this', 'movie', 'will', 'not', 'be', 'liked', 'by', 'most', 'people', ',', 'these', 'people', 'will', 'think', 'like', 'i', 'did', 'that', 'this', 'movie', 'is', 'stupid', 'and', 'pointless', '.', 'but', 'if', 'you', 'like', 'the', 'tv', 'show', 'you', 'might', 'actually', 'like', 'this', 'movie', '.', 'but', 'to', 'be', 'on', 'the', 'safe', 'side', 'i', 'am', 'opting', 'to', 'recommend', 'you', 'save', 'your', 'money', 'and', 'not', 'go', 'to', 'see', 'this', 'movie', '.', 'there', 'are', 'many', 'movies', 'that', 'are', 'truly', 'worth', 'seeing', 'unlike', 'this', 'one', '.'], 'neg')\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 5.2 Feature Extraction\n",
    "\n",
    "We‚Äôll define features as whether a given word is present in a document."
   ],
   "id": "2dbfa29e654e529e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:50.977004Z",
     "start_time": "2025-04-23T18:25:50.266599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "all_words = FreqDist(w.lower() for w in movie_reviews.words())\n",
    "all_words"
   ],
   "id": "366673d5159e2b42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 77717, 'the': 76529, '.': 65876, 'a': 38106, 'and': 35576, 'of': 34123, 'to': 31937, \"'\": 30585, 'is': 25195, 'in': 21822, ...})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:50.990295Z",
     "start_time": "2025-04-23T18:25:50.983093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_features = list(all_words)[:2000]\n",
    "print('Top 20 features:', word_features[:20])"
   ],
   "id": "a2e6e8b2974dca99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features: [',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-', ')', '(', 'as', 'with', 'for']\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:50.998694Z",
     "start_time": "2025-04-23T18:25:50.996165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# Apply to the first document, documents[0][0] is list of words\n",
    "features = document_features(documents[0][0])\n",
    "print('Length of features:', len(features))\n",
    "print('Features:', features)"
   ],
   "id": "a034cb4b32be7b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of features: 2000\n",
      "Features: {'contains(,)': True, 'contains(the)': True, 'contains(.)': True, 'contains(a)': True, 'contains(and)': True, 'contains(of)': True, 'contains(to)': True, \"contains(')\": True, 'contains(is)': True, 'contains(in)': True, 'contains(s)': True, 'contains(\")': False, 'contains(it)': True, 'contains(that)': True, 'contains(-)': True, 'contains())': False, 'contains(()': False, 'contains(as)': True, 'contains(with)': True, 'contains(for)': True, 'contains(his)': False, 'contains(this)': True, 'contains(film)': False, 'contains(i)': True, 'contains(he)': False, 'contains(but)': True, 'contains(on)': True, 'contains(are)': True, 'contains(t)': True, 'contains(by)': True, 'contains(be)': True, 'contains(one)': True, 'contains(movie)': True, 'contains(an)': False, 'contains(who)': False, 'contains(not)': True, 'contains(you)': True, 'contains(from)': True, 'contains(at)': True, 'contains(was)': True, 'contains(have)': True, 'contains(they)': True, 'contains(has)': True, 'contains(her)': False, 'contains(all)': False, 'contains(?)': False, 'contains(there)': True, 'contains(like)': True, 'contains(so)': True, 'contains(out)': True, 'contains(about)': True, 'contains(up)': True, 'contains(more)': True, 'contains(what)': True, 'contains(when)': True, 'contains(which)': False, 'contains(or)': True, 'contains(she)': False, 'contains(their)': False, 'contains(:)': False, 'contains(some)': True, 'contains(just)': True, 'contains(can)': True, 'contains(if)': True, 'contains(we)': False, 'contains(him)': False, 'contains(into)': True, 'contains(even)': True, 'contains(only)': True, 'contains(than)': True, 'contains(no)': True, 'contains(good)': False, 'contains(time)': False, 'contains(most)': True, 'contains(its)': True, 'contains(will)': True, 'contains(story)': True, 'contains(would)': True, 'contains(been)': True, 'contains(much)': True, 'contains(character)': True, 'contains(also)': False, 'contains(get)': True, 'contains(other)': True, 'contains(do)': True, 'contains(two)': True, 'contains(well)': True, 'contains(them)': False, 'contains(very)': True, 'contains(characters)': False, 'contains(;)': False, 'contains(first)': True, 'contains(--)': False, 'contains(after)': False, 'contains(see)': True, 'contains(!)': False, 'contains(way)': True, 'contains(because)': True, 'contains(make)': False, 'contains(life)': False, 'contains(off)': True, 'contains(too)': True, 'contains(any)': True, 'contains(does)': False, 'contains(really)': True, 'contains(had)': True, 'contains(while)': False, 'contains(films)': False, 'contains(how)': True, 'contains(plot)': True, 'contains(little)': True, 'contains(where)': False, 'contains(people)': True, 'contains(over)': False, 'contains(could)': True, 'contains(then)': True, 'contains(me)': False, 'contains(scene)': False, 'contains(man)': False, 'contains(bad)': True, 'contains(my)': True, 'contains(never)': False, 'contains(being)': False, 'contains(best)': True, 'contains(these)': True, 'contains(don)': True, 'contains(new)': False, 'contains(doesn)': False, 'contains(scenes)': False, 'contains(many)': True, 'contains(director)': False, 'contains(such)': False, 'contains(know)': True, 'contains(were)': False, 'contains(movies)': True, 'contains(through)': True, 'contains(here)': False, 'contains(action)': False, 'contains(great)': False, 'contains(re)': False, 'contains(another)': True, 'contains(love)': False, 'contains(go)': True, 'contains(made)': False, 'contains(us)': False, 'contains(big)': True, 'contains(end)': True, 'contains(something)': True, 'contains(back)': False, 'contains(*)': False, 'contains(still)': False, 'contains(world)': False, 'contains(seems)': True, 'contains(work)': False, 'contains(those)': True, 'contains(makes)': False, 'contains(now)': True, 'contains(before)': False, 'contains(however)': False, 'contains(between)': False, 'contains(few)': False, 'contains(/)': False, 'contains(down)': False, 'contains(every)': False, 'contains(though)': False, 'contains(better)': True, 'contains(real)': True, 'contains(audience)': True, 'contains(enough)': True, 'contains(seen)': False, 'contains(take)': False, 'contains(around)': False, 'contains(both)': False, 'contains(going)': True, 'contains(year)': False, 'contains(performance)': False, 'contains(why)': False, 'contains(should)': True, 'contains(role)': True, 'contains(isn)': True, 'contains(same)': False, 'contains(old)': False, 'contains(gets)': False, 'contains(your)': True, 'contains(may)': False, 'contains(things)': True, 'contains(think)': True, 'contains(years)': False, 'contains(last)': False, 'contains(comedy)': True, 'contains(funny)': True, 'contains(actually)': True, 'contains(ve)': False, 'contains(long)': False, 'contains(look)': True, 'contains(almost)': False, 'contains(own)': False, 'contains(thing)': True, 'contains(fact)': False, 'contains(nothing)': False, 'contains(say)': True, 'contains(right)': False, 'contains(john)': False, 'contains(although)': True, 'contains(played)': False, 'contains(find)': False, 'contains(script)': False, 'contains(come)': False, 'contains(ever)': False, 'contains(cast)': False, 'contains(since)': False, 'contains(did)': True, 'contains(star)': True, 'contains(plays)': False, 'contains(young)': False, 'contains(show)': True, 'contains(comes)': False, 'contains(m)': False, 'contains(part)': False, 'contains(original)': False, 'contains(actors)': True, 'contains(screen)': True, 'contains(without)': False, 'contains(again)': True, 'contains(acting)': True, 'contains(three)': False, 'contains(day)': False, 'contains(each)': False, 'contains(point)': False, 'contains(lot)': False, 'contains(least)': True, 'contains(takes)': False, 'contains(guy)': False, 'contains(quite)': True, 'contains(himself)': False, 'contains(away)': False, 'contains(during)': True, 'contains(family)': False, 'contains(effects)': False, 'contains(course)': False, 'contains(goes)': True, 'contains(minutes)': False, 'contains(interesting)': True, 'contains(might)': True, 'contains(far)': False, 'contains(high)': False, 'contains(rather)': True, 'contains(once)': False, 'contains(must)': True, 'contains(anything)': True, 'contains(place)': False, 'contains(set)': False, 'contains(yet)': False, 'contains(watch)': False, 'contains(d)': False, 'contains(making)': False, 'contains(our)': False, 'contains(wife)': False, 'contains(hard)': True, 'contains(always)': False, 'contains(fun)': False, 'contains(didn)': True, 'contains(ll)': False, 'contains(seem)': False, 'contains(special)': False, 'contains(bit)': True, 'contains(times)': False, 'contains(trying)': True, 'contains(hollywood)': False, 'contains(instead)': False, 'contains(give)': False, 'contains(want)': False, 'contains(picture)': False, 'contains(kind)': False, 'contains(american)': True, 'contains(job)': True, 'contains(sense)': False, 'contains(woman)': False, 'contains(home)': False, 'contains(having)': False, 'contains(series)': True, 'contains(actor)': True, 'contains(probably)': True, 'contains(help)': True, 'contains(half)': False, 'contains(along)': False, 'contains(men)': False, 'contains(everything)': False, 'contains(pretty)': False, 'contains(becomes)': False, 'contains(sure)': True, 'contains(black)': False, 'contains(together)': False, 'contains(dialogue)': True, 'contains(money)': True, 'contains(become)': False, 'contains(gives)': False, 'contains(given)': False, 'contains(looking)': False, 'contains(whole)': True, 'contains(watching)': False, 'contains(father)': False, 'contains(`)': False, 'contains(feel)': False, 'contains(everyone)': False, 'contains(music)': False, 'contains(wants)': False, 'contains(sex)': False, 'contains(less)': False, 'contains(done)': True, 'contains(horror)': False, 'contains(got)': False, 'contains(death)': False, 'contains(perhaps)': False, 'contains(city)': False, 'contains(next)': False, 'contains(especially)': False, 'contains(play)': False, 'contains(girl)': False, 'contains(mind)': False, 'contains(10)': False, 'contains(moments)': True, 'contains(looks)': False, 'contains(completely)': False, 'contains(2)': False, 'contains(reason)': False, 'contains(mother)': False, 'contains(whose)': False, 'contains(line)': True, 'contains(night)': False, 'contains(human)': False, 'contains(until)': False, 'contains(rest)': True, 'contains(performances)': False, 'contains(different)': True, 'contains(evil)': False, 'contains(small)': False, 'contains(james)': False, 'contains(simply)': True, 'contains(couple)': True, 'contains(put)': False, 'contains(let)': True, 'contains(anyone)': False, 'contains(ending)': False, 'contains(case)': False, 'contains(several)': False, 'contains(dead)': False, 'contains(michael)': False, 'contains(left)': False, 'contains(thought)': True, 'contains(school)': False, 'contains(shows)': True, 'contains(humor)': True, 'contains(true)': False, 'contains(lost)': False, 'contains(written)': False, 'contains(itself)': False, 'contains(friend)': False, 'contains(entire)': False, 'contains(getting)': True, 'contains(town)': False, 'contains(turns)': False, 'contains(soon)': False, 'contains(someone)': False, 'contains(second)': False, 'contains(main)': False, 'contains(stars)': False, 'contains(found)': False, 'contains(use)': False, 'contains(problem)': False, 'contains(friends)': False, 'contains(tv)': True, 'contains(top)': False, 'contains(name)': False, 'contains(begins)': False, 'contains(called)': False, 'contains(based)': True, 'contains(comic)': False, 'contains(david)': False, 'contains(head)': False, 'contains(else)': False, 'contains(idea)': False, 'contains(either)': True, 'contains(wrong)': True, 'contains(unfortunately)': False, 'contains(later)': False, 'contains(final)': False, 'contains(hand)': False, 'contains(alien)': False, 'contains(house)': False, 'contains(group)': False, 'contains(full)': False, 'contains(used)': False, 'contains(tries)': False, 'contains(often)': False, 'contains(against)': False, 'contains(war)': False, 'contains(sequence)': False, 'contains(keep)': False, 'contains(turn)': False, 'contains(playing)': False, 'contains(boy)': False, 'contains(behind)': False, 'contains(named)': False, 'contains(certainly)': False, 'contains(live)': False, 'contains(believe)': False, 'contains(under)': False, 'contains(works)': False, 'contains(relationship)': False, 'contains(face)': False, 'contains(hour)': False, 'contains(run)': False, 'contains(style)': True, 'contains(said)': True, 'contains(despite)': False, 'contains(person)': False, 'contains(finally)': False, 'contains(shot)': False, 'contains(book)': False, 'contains(doing)': False, 'contains(tell)': False, 'contains(maybe)': False, 'contains(nice)': False, 'contains(son)': False, 'contains(perfect)': False, 'contains(side)': True, 'contains(seeing)': True, 'contains(able)': False, 'contains(finds)': False, 'contains(children)': False, 'contains(days)': False, 'contains(past)': False, 'contains(summer)': False, 'contains(camera)': False, 'contains(won)': False, 'contains(including)': False, 'contains(mr)': True, 'contains(kids)': False, 'contains(lives)': False, 'contains(directed)': False, 'contains(moment)': False, 'contains(game)': False, 'contains(running)': False, 'contains(fight)': False, 'contains(supposed)': False, 'contains(video)': False, 'contains(car)': False, 'contains(matter)': False, 'contains(kevin)': False, 'contains(joe)': False, 'contains(lines)': False, 'contains(worth)': True, 'contains(=)': False, 'contains(daughter)': False, 'contains(earth)': False, 'contains(starts)': False, 'contains(need)': False, 'contains(entertaining)': False, 'contains(white)': False, 'contains(start)': False, 'contains(writer)': False, 'contains(dark)': False, 'contains(short)': False, 'contains(self)': False, 'contains(worst)': False, 'contains(nearly)': False, 'contains(opening)': False, 'contains(try)': False, 'contains(upon)': False, 'contains(care)': False, 'contains(early)': False, 'contains(violence)': False, 'contains(throughout)': False, 'contains(team)': False, 'contains(production)': False, 'contains(example)': False, 'contains(beautiful)': False, 'contains(title)': False, 'contains(exactly)': False, 'contains(jack)': False, 'contains(review)': False, 'contains(major)': False, 'contains(drama)': False, 'contains(&)': False, 'contains(problems)': False, 'contains(sequences)': False, 'contains(obvious)': False, 'contains(version)': False, 'contains(screenplay)': False, 'contains(known)': True, 'contains(killer)': False, 'contains(wasn)': True, 'contains(robert)': False, 'contains(disney)': False, 'contains(already)': False, 'contains(close)': True, 'contains(classic)': False, 'contains(others)': False, 'contains(hit)': False, 'contains(kill)': False, 'contains(deep)': False, 'contains(five)': False, 'contains(order)': False, 'contains(act)': True, 'contains(simple)': False, 'contains(fine)': False, 'contains(themselves)': False, 'contains(heart)': False, 'contains(roles)': False, 'contains(jackie)': False, 'contains(direction)': False, 'contains(eyes)': False, 'contains(four)': False, 'contains(question)': False, 'contains(sort)': False, 'contains(sometimes)': False, 'contains(knows)': False, 'contains(supporting)': False, 'contains(coming)': True, 'contains(voice)': False, 'contains(women)': False, 'contains(truly)': True, 'contains(save)': True, 'contains(jokes)': False, 'contains(computer)': False, 'contains(child)': False, 'contains(o)': False, 'contains(boring)': False, 'contains(tom)': False, 'contains(level)': False, 'contains(1)': False, 'contains(body)': False, 'contains(guys)': False, 'contains(genre)': False, 'contains(brother)': False, 'contains(strong)': False, 'contains(stop)': False, 'contains(room)': False, 'contains(space)': False, 'contains(lee)': False, 'contains(ends)': False, 'contains(beginning)': False, 'contains(ship)': False, 'contains(york)': False, 'contains(attempt)': False, 'contains(thriller)': False, 'contains(scream)': False, 'contains(peter)': False, 'contains(aren)': False, 'contains(husband)': False, 'contains(fiction)': False, 'contains(happens)': False, 'contains(hero)': False, 'contains(novel)': False, 'contains(note)': False, 'contains(hope)': False, 'contains(king)': False, 'contains(yes)': False, 'contains(says)': False, 'contains(tells)': False, 'contains(quickly)': False, 'contains(romantic)': False, 'contains(dog)': False, 'contains(oscar)': False, 'contains(stupid)': True, 'contains(possible)': False, 'contains(saw)': False, 'contains(lead)': False, 'contains(career)': False, 'contains(murder)': False, 'contains(extremely)': False, 'contains(manages)': False, 'contains(god)': False, 'contains(mostly)': False, 'contains(wonder)': False, 'contains(particularly)': False, 'contains(future)': False, 'contains(fans)': False, 'contains(sound)': False, 'contains(worse)': False, 'contains(piece)': False, 'contains(involving)': False, 'contains(de)': False, 'contains(appears)': False, 'contains(planet)': False, 'contains(paul)': False, 'contains(involved)': False, 'contains(mean)': False, 'contains(none)': False, 'contains(taking)': False, 'contains(hours)': False, 'contains(laugh)': False, 'contains(police)': False, 'contains(sets)': False, 'contains(attention)': False, 'contains(co)': False, 'contains(hell)': False, 'contains(eventually)': False, 'contains(single)': False, 'contains(fall)': False, 'contains(falls)': False, 'contains(material)': False, 'contains(emotional)': False, 'contains(power)': False, 'contains(late)': False, 'contains(lack)': False, 'contains(dr)': False, 'contains(van)': False, 'contains(result)': False, 'contains(elements)': False, 'contains(meet)': False, 'contains(smith)': False, 'contains(science)': False, 'contains(experience)': False, 'contains(bring)': False, 'contains(wild)': False, 'contains(living)': False, 'contains(theater)': False, 'contains(interest)': False, 'contains(leads)': False, 'contains(word)': False, 'contains(feature)': False, 'contains(battle)': False, 'contains(girls)': False, 'contains(alone)': False, 'contains(obviously)': False, 'contains(george)': False, 'contains(within)': False, 'contains(usually)': True, 'contains(enjoy)': True, 'contains(guess)': False, 'contains(among)': False, 'contains(taken)': False, 'contains(feeling)': False, 'contains(laughs)': False, 'contains(aliens)': False, 'contains(talk)': False, 'contains(chance)': False, 'contains(talent)': False, 'contains(3)': False, 'contains(middle)': False, 'contains(number)': False, 'contains(easy)': False, 'contains(across)': False, 'contains(needs)': False, 'contains(attempts)': False, 'contains(happen)': False, 'contains(television)': False, 'contains(chris)': False, 'contains(deal)': False, 'contains(poor)': True, 'contains(form)': True, 'contains(girlfriend)': False, 'contains(viewer)': False, 'contains(release)': False, 'contains(killed)': False, 'contains(forced)': False, 'contains(whether)': False, 'contains(wonderful)': False, 'contains(feels)': False, 'contains(oh)': False, 'contains(tale)': False, 'contains(serious)': False, 'contains(expect)': False, 'contains(except)': False, 'contains(light)': False, 'contains(success)': False, 'contains(features)': False, 'contains(premise)': True, 'contains(happy)': False, 'contains(words)': True, 'contains(leave)': False, 'contains(important)': False, 'contains(meets)': False, 'contains(history)': False, 'contains(giving)': False, 'contains(crew)': False, 'contains(type)': False, 'contains(call)': False, 'contains(turned)': False, 'contains(released)': False, 'contains(parents)': False, 'contains(art)': False, 'contains(impressive)': False, 'contains(mission)': False, 'contains(working)': False, 'contains(seemed)': True, 'contains(score)': False, 'contains(told)': False, 'contains(recent)': False, 'contains(robin)': False, 'contains(basically)': False, 'contains(entertainment)': False, 'contains(america)': True, 'contains($)': False, 'contains(surprise)': False, 'contains(apparently)': False, 'contains(easily)': False, 'contains(ryan)': False, 'contains(cool)': False, 'contains(stuff)': False, 'contains(cop)': False, 'contains(change)': False, 'contains(williams)': False, 'contains(crime)': False, 'contains(office)': False, 'contains(parts)': False, 'contains(somehow)': False, 'contains(sequel)': False, 'contains(william)': False, 'contains(cut)': False, 'contains(die)': False, 'contains(jones)': False, 'contains(credits)': False, 'contains(batman)': False, 'contains(suspense)': False, 'contains(brings)': False, 'contains(events)': False, 'contains(reality)': False, 'contains(whom)': False, 'contains(local)': False, 'contains(talking)': False, 'contains(difficult)': False, 'contains(using)': False, 'contains(went)': True, 'contains(writing)': False, 'contains(remember)': False, 'contains(near)': False, 'contains(straight)': False, 'contains(hilarious)': False, 'contains(ago)': False, 'contains(certain)': False, 'contains(ben)': False, 'contains(kid)': False, 'contains(wouldn)': False, 'contains(slow)': False, 'contains(blood)': False, 'contains(mystery)': False, 'contains(complete)': False, 'contains(red)': False, 'contains(popular)': False, 'contains(effective)': False, 'contains(am)': True, 'contains(fast)': False, 'contains(flick)': True, 'contains(due)': False, 'contains(runs)': False, 'contains(gone)': True, 'contains(return)': False, 'contains(presence)': False, 'contains(quality)': False, 'contains(dramatic)': False, 'contains(filmmakers)': False, 'contains(age)': False, 'contains(brothers)': False, 'contains(business)': False, 'contains(general)': False, 'contains(rock)': False, 'contains(sexual)': False, 'contains(present)': False, 'contains(surprisingly)': False, 'contains(anyway)': False, 'contains(uses)': False, 'contains(4)': False, 'contains(personal)': False, 'contains(figure)': False, 'contains(smart)': False, 'contains(ways)': False, 'contains(decides)': False, 'contains(annoying)': False, 'contains(begin)': False, 'contains(couldn)': False, 'contains(somewhat)': False, 'contains(shots)': False, 'contains(rich)': False, 'contains(minute)': False, 'contains(law)': False, 'contains(previous)': False, 'contains(jim)': False, 'contains(successful)': False, 'contains(harry)': False, 'contains(water)': False, 'contains(similar)': False, 'contains(absolutely)': False, 'contains(motion)': False, 'contains(former)': False, 'contains(strange)': False, 'contains(came)': False, 'contains(follow)': False, 'contains(read)': False, 'contains(project)': False, 'contains(million)': False, 'contains(secret)': False, 'contains(starring)': False, 'contains(clear)': False, 'contains(familiar)': False, 'contains(romance)': False, 'contains(intelligent)': False, 'contains(third)': False, 'contains(excellent)': False, 'contains(amazing)': False, 'contains(party)': False, 'contains(budget)': False, 'contains(eye)': False, 'contains(actress)': False, 'contains(prison)': False, 'contains(latest)': False, 'contains(means)': False, 'contains(company)': False, 'contains(towards)': False, 'contains(predictable)': False, 'contains(powerful)': False, 'contains(nor)': False, 'contains(bob)': False, 'contains(beyond)': False, 'contains(visual)': False, 'contains(leaves)': False, 'contains(r)': False, 'contains(nature)': False, 'contains(following)': False, 'contains(villain)': False, 'contains(leaving)': False, 'contains(animated)': False, 'contains(low)': False, 'contains(myself)': False, 'contains(b)': False, 'contains(bill)': False, 'contains(sam)': False, 'contains(filled)': False, 'contains(wars)': False, 'contains(questions)': False, 'contains(cinema)': False, 'contains(message)': False, 'contains(box)': False, 'contains(moving)': False, 'contains(herself)': False, 'contains(country)': False, 'contains(usual)': False, 'contains(martin)': False, 'contains(definitely)': False, 'contains(add)': False, 'contains(large)': False, 'contains(clever)': False, 'contains(create)': False, 'contains(felt)': False, 'contains(stories)': False, 'contains(brilliant)': False, 'contains(ones)': False, 'contains(giant)': False, 'contains(situation)': False, 'contains(murphy)': False, 'contains(break)': False, 'contains(opens)': False, 'contains(scary)': False, 'contains(doubt)': False, 'contains(drug)': False, 'contains(bunch)': False, 'contains(thinking)': False, 'contains(solid)': False, 'contains(effect)': True, 'contains(learn)': False, 'contains(move)': False, 'contains(force)': False, 'contains(potential)': False, 'contains(seriously)': True, 'contains(follows)': False, 'contains(above)': False, 'contains(saying)': False, 'contains(huge)': False, 'contains(class)': False, 'contains(plan)': False, 'contains(agent)': False, 'contains(created)': False, 'contains(unlike)': True, 'contains(pay)': False, 'contains(non)': False, 'contains(married)': False, 'contains(mark)': False, 'contains(sweet)': False, 'contains(perfectly)': False, 'contains(ex)': False, 'contains(realize)': False, 'contains(audiences)': False, 'contains(took)': False, 'contains(decent)': False, 'contains(likely)': False, 'contains(dream)': False, 'contains(view)': False, 'contains(scott)': False, 'contains(subject)': False, 'contains(understand)': False, 'contains(happened)': False, 'contains(enjoyable)': False, 'contains(studio)': False, 'contains(immediately)': False, 'contains(open)': False, 'contains(e)': False, 'contains(points)': False, 'contains(heard)': False, 'contains(viewers)': False, 'contains(cameron)': False, 'contains(truman)': False, 'contains(bruce)': False, 'contains(frank)': False, 'contains(private)': False, 'contains(stay)': True, 'contains(fails)': True, 'contains(impossible)': False, 'contains(cold)': False, 'contains(richard)': False, 'contains(overall)': True, 'contains(merely)': False, 'contains(exciting)': False, 'contains(mess)': False, 'contains(chase)': False, 'contains(free)': False, 'contains(ten)': False, 'contains(neither)': False, 'contains(wanted)': False, 'contains(gun)': False, 'contains(appear)': False, 'contains(carter)': False, 'contains(escape)': False, 'contains(ultimately)': False, 'contains(+)': False, 'contains(fan)': False, 'contains(inside)': False, 'contains(favorite)': False, 'contains(haven)': False, 'contains(modern)': False, 'contains(l)': False, 'contains(wedding)': False, 'contains(stone)': False, 'contains(trek)': True, 'contains(brought)': False, 'contains(trouble)': False, 'contains(otherwise)': False, 'contains(tim)': False, 'contains(5)': False, 'contains(allen)': False, 'contains(bond)': False, 'contains(society)': False, 'contains(liked)': True, 'contains(dumb)': False, 'contains(musical)': False, 'contains(stand)': False, 'contains(political)': False, 'contains(various)': False, 'contains(talented)': False, 'contains(particular)': False, 'contains(west)': False, 'contains(state)': True, 'contains(keeps)': False, 'contains(english)': False, 'contains(silly)': False, 'contains(u)': False, 'contains(situations)': False, 'contains(park)': False, 'contains(teen)': False, 'contains(rating)': False, 'contains(slightly)': False, 'contains(steve)': False, 'contains(truth)': False, 'contains(air)': False, 'contains(element)': False, 'contains(joke)': False, 'contains(spend)': False, 'contains(key)': False, 'contains(biggest)': False, 'contains(members)': False, 'contains(effort)': False, 'contains(government)': False, 'contains(focus)': False, 'contains(eddie)': False, 'contains(soundtrack)': False, 'contains(hands)': False, 'contains(earlier)': False, 'contains(chan)': False, 'contains(purpose)': False, 'contains(today)': False, 'contains(showing)': False, 'contains(memorable)': False, 'contains(six)': False, 'contains(cannot)': False, 'contains(max)': False, 'contains(offers)': False, 'contains(rated)': False, 'contains(mars)': False, 'contains(heavy)': False, 'contains(totally)': False, 'contains(control)': False, 'contains(credit)': False, 'contains(fi)': False, 'contains(woody)': False, 'contains(ideas)': False, 'contains(sci)': False, 'contains(wait)': False, 'contains(sit)': False, 'contains(female)': False, 'contains(ask)': False, 'contains(waste)': False, 'contains(terrible)': False, 'contains(depth)': False, 'contains(simon)': False, 'contains(aspect)': False, 'contains(list)': False, 'contains(mary)': False, 'contains(sister)': False, 'contains(animation)': False, 'contains(entirely)': False, 'contains(fear)': False, 'contains(steven)': False, 'contains(moves)': False, 'contains(actual)': False, 'contains(army)': False, 'contains(british)': False, 'contains(constantly)': False, 'contains(fire)': False, 'contains(convincing)': False, 'contains(setting)': False, 'contains(gave)': False, 'contains(tension)': False, 'contains(street)': False, 'contains(8)': False, 'contains(brief)': False, 'contains(ridiculous)': False, 'contains(cinematography)': False, 'contains(typical)': False, 'contains(nick)': False, 'contains(screenwriter)': False, 'contains(ability)': False, 'contains(spent)': False, 'contains(quick)': False, 'contains(violent)': False, 'contains(atmosphere)': False, 'contains(subtle)': False, 'contains(expected)': False, 'contains(fairly)': True, 'contains(seven)': False, 'contains(killing)': False, 'contains(tone)': False, 'contains(master)': False, 'contains(disaster)': False, 'contains(lots)': False, 'contains(thinks)': False, 'contains(song)': False, 'contains(cheap)': False, 'contains(suddenly)': False, 'contains(background)': False, 'contains(club)': False, 'contains(willis)': False, 'contains(whatever)': False, 'contains(highly)': False, 'contains(sees)': False, 'contains(complex)': False, 'contains(greatest)': False, 'contains(impact)': False, 'contains(beauty)': False, 'contains(front)': False, 'contains(humans)': False, 'contains(indeed)': False, 'contains(flat)': False, 'contains(grace)': False, 'contains(wrote)': False, 'contains(amusing)': False, 'contains(ii)': False, 'contains(mike)': False, 'contains(further)': False, 'contains(cute)': False, 'contains(dull)': False, 'contains(minor)': False, 'contains(recently)': False, 'contains(hate)': False, 'contains(outside)': False, 'contains(plenty)': False, 'contains(wish)': False, 'contains(godzilla)': False, 'contains(college)': False, 'contains(titanic)': False, 'contains(sounds)': False, 'contains(telling)': False, 'contains(sight)': False, 'contains(double)': False, 'contains(cinematic)': False, 'contains(queen)': False, 'contains(hold)': False, 'contains(meanwhile)': False, 'contains(awful)': False, 'contains(clearly)': False, 'contains(theme)': False, 'contains(hear)': False, 'contains(x)': False, 'contains(amount)': False, 'contains(baby)': False, 'contains(approach)': False, 'contains(dreams)': False, 'contains(shown)': False, 'contains(island)': False, 'contains(reasons)': False, 'contains(charm)': False, 'contains(miss)': False, 'contains(longer)': False, 'contains(common)': False, 'contains(sean)': False, 'contains(carry)': False, 'contains(believable)': False, 'contains(realistic)': False, 'contains(chemistry)': False, 'contains(possibly)': False, 'contains(casting)': True, 'contains(carrey)': False, 'contains(french)': False, 'contains(trailer)': False, 'contains(tough)': False, 'contains(produced)': False, 'contains(imagine)': False, 'contains(choice)': False, 'contains(ride)': True, 'contains(somewhere)': False, 'contains(hot)': False, 'contains(race)': False, 'contains(road)': False, 'contains(leader)': False, 'contains(thin)': False, 'contains(jerry)': False, 'contains(slowly)': False, 'contains(delivers)': False, 'contains(detective)': False, 'contains(brown)': False, 'contains(jackson)': False, 'contains(member)': False, 'contains(provide)': False, 'contains(president)': False, 'contains(puts)': False, 'contains(asks)': False, 'contains(critics)': False, 'contains(appearance)': False, 'contains(famous)': False, 'contains(okay)': False, 'contains(intelligence)': False, 'contains(energy)': False, 'contains(sent)': True, 'contains(spielberg)': False, 'contains(development)': False, 'contains(etc)': False, 'contains(language)': False, 'contains(blue)': False, 'contains(proves)': False, 'contains(vampire)': False, 'contains(seemingly)': False, 'contains(basic)': False, 'contains(caught)': False, 'contains(decide)': False, 'contains(opportunity)': False, 'contains(incredibly)': False, 'contains(images)': False, 'contains(band)': False, 'contains(j)': False, 'contains(writers)': False, 'contains(knew)': False, 'contains(interested)': False, 'contains(considering)': False, 'contains(boys)': False, 'contains(thanks)': False, 'contains(remains)': False, 'contains(climax)': False, 'contains(event)': False, 'contains(directing)': False, 'contains(conclusion)': False, 'contains(leading)': False, 'contains(ground)': False, 'contains(lies)': False, 'contains(forget)': False, 'contains(alive)': False, 'contains(tarzan)': False, 'contains(century)': False, 'contains(provides)': False, 'contains(trip)': True, 'contains(partner)': False, 'contains(central)': False, 'contains(tarantino)': False, 'contains(period)': False, 'contains(pace)': False, 'contains(yourself)': False, 'contains(worked)': False, 'contains(ready)': False, 'contains(date)': False, 'contains(thus)': False, 'contains(1998)': False, 'contains(terrific)': False, 'contains(write)': False, 'contains(average)': False, 'contains(onto)': False, 'contains(songs)': False, 'contains(occasionally)': False, 'contains(doctor)': False, 'contains(stands)': False, 'contains(hardly)': False, 'contains(monster)': False, 'contains(led)': False, 'contains(mysterious)': False, 'contains(details)': False, 'contains(wasted)': False, 'contains(apart)': False, 'contains(aside)': False, 'contains(store)': False, 'contains(billy)': False, 'contains(boss)': False, 'contains(travolta)': False, 'contains(producer)': False, 'contains(pull)': False, 'contains(consider)': False, 'contains(pictures)': False, 'contains(becoming)': False, 'contains(cage)': False, 'contains(loud)': False, 'contains(looked)': False, 'contains(officer)': False, 'contains(twenty)': False, 'contains(system)': False, 'contains(contains)': False, 'contains(julia)': False, 'contains(subplot)': False, 'contains(missing)': False, 'contains(personality)': False, 'contains(building)': False, 'contains(learns)': False, 'contains(hong)': False, 'contains(la)': True, 'contains(apartment)': False, 'contains(7)': False, 'contains(bizarre)': False, 'contains(powers)': False, 'contains(flaws)': False, 'contains(catch)': False, 'contains(lawyer)': False, 'contains(shoot)': False, 'contains(student)': False, 'contains(unique)': False, 'contains(000)': False, 'contains(admit)': False, 'contains(concept)': False, 'contains(needed)': False, 'contains(thrown)': False, 'contains(christopher)': False, 'contains(laughing)': True, 'contains(green)': False, 'contains(twists)': False, 'contains(matthew)': False, 'contains(touch)': False, 'contains(waiting)': False, 'contains(victim)': False, 'contains(cover)': False, 'contains(machine)': False, 'contains(danny)': False, 'contains(mention)': False, 'contains(search)': False, 'contains(1997)': False, 'contains(win)': False, 'contains(door)': False, 'contains(manner)': True, 'contains(train)': False, 'contains(saving)': False, 'contains(share)': False, 'contains(image)': False, 'contains(discovers)': False, 'contains(normal)': False, 'contains(cross)': False, 'contains(fox)': False, 'contains(returns)': False, 'contains(adult)': False, 'contains(adds)': False, 'contains(answer)': False, 'contains(adventure)': False, 'contains(lame)': False, 'contains(male)': False, 'contains(odd)': True, 'contains(singer)': False, 'contains(deserves)': False, 'contains(gore)': False, 'contains(states)': False, 'contains(include)': False, 'contains(equally)': False, 'contains(months)': False, 'contains(barely)': False, 'contains(directors)': False, 'contains(introduced)': False, 'contains(fashion)': False, 'contains(social)': False, 'contains(1999)': False, 'contains(news)': False, 'contains(hair)': False, 'contains(dance)': False, 'contains(innocent)': False, 'contains(camp)': False, 'contains(teacher)': False, 'contains(became)': False, 'contains(sad)': False, 'contains(witch)': False, 'contains(includes)': False, 'contains(nights)': False, 'contains(jason)': False, 'contains(julie)': False, 'contains(latter)': False, 'contains(food)': False, 'contains(jennifer)': False, 'contains(land)': False, 'contains(menace)': False, 'contains(rate)': False, 'contains(storyline)': False, 'contains(contact)': False, 'contains(jean)': False, 'contains(elizabeth)': False, 'contains(fellow)': False, 'contains(changes)': False, 'contains(henry)': False, 'contains(hill)': False, 'contains(pulp)': False, 'contains(gay)': False, 'contains(tried)': False, 'contains(surprised)': False, 'contains(literally)': False, 'contains(walk)': False, 'contains(standard)': False, 'contains(90)': False, 'contains(forward)': False, 'contains(wise)': False, 'contains(enjoyed)': False, 'contains(discover)': False, 'contains(pop)': False, 'contains(anderson)': False, 'contains(offer)': False, 'contains(recommend)': True, 'contains(public)': False, 'contains(drive)': False, 'contains(c)': False, 'contains(toy)': False, 'contains(charming)': False, 'contains(fair)': False, 'contains(chinese)': False, 'contains(rescue)': False, 'contains(terms)': False, 'contains(mouth)': False, 'contains(lucas)': False, 'contains(accident)': False, 'contains(dies)': False, 'contains(decided)': False, 'contains(edge)': False, 'contains(footage)': False, 'contains(culture)': False, 'contains(weak)': False, 'contains(presented)': False, 'contains(blade)': False, 'contains(younger)': False, 'contains(douglas)': False, 'contains(natural)': False, 'contains(born)': False, 'contains(generally)': False, 'contains(teenage)': False, 'contains(older)': False, 'contains(horrible)': False, 'contains(addition)': False, 'contains(sadly)': False, 'contains(creates)': False, 'contains(disturbing)': False, 'contains(roger)': False, 'contains(detail)': False, 'contains(devil)': False, 'contains(debut)': False, 'contains(track)': False, 'contains(developed)': False, 'contains(week)': False, 'contains(russell)': False, 'contains(attack)': False, 'contains(explain)': False, 'contains(rarely)': False, 'contains(fully)': False, 'contains(prove)': False, 'contains(exception)': False, 'contains(jeff)': False, 'contains(twist)': False, 'contains(gang)': False, 'contains(winning)': False, 'contains(jr)': False, 'contains(species)': False, 'contains(issues)': False, 'contains(fresh)': False, 'contains(rules)': False, 'contains(meaning)': False, 'contains(inspired)': False, 'contains(heroes)': False, 'contains(desperate)': False, 'contains(fighting)': False, 'contains(filmed)': False, 'contains(faces)': False, 'contains(alan)': False, 'contains(bright)': False, 'contains(ass)': False, 'contains(flying)': False, 'contains(kong)': False, 'contains(rush)': False, 'contains(forces)': False, 'contains(charles)': False, 'contains(numerous)': False, 'contains(emotions)': False, 'contains(involves)': False, 'contains(patrick)': False, 'contains(weird)': False, 'contains(apparent)': False, 'contains(information)': False, 'contains(revenge)': False, 'contains(jay)': False, 'contains(toward)': False, 'contains(surprising)': False, 'contains(twice)': False, 'contains(editing)': False, 'contains(calls)': False, 'contains(lose)': False, 'contains(vegas)': False, 'contains(stage)': False, 'contains(intended)': False, 'contains(gags)': False, 'contains(opinion)': False, 'contains(likes)': False, 'contains(crazy)': False, 'contains(owner)': False, 'contains(places)': False, 'contains(pair)': False, 'contains(genuine)': False, 'contains(epic)': False, 'contains(speak)': False, 'contains(throw)': False, 'contains(appeal)': False, 'contains(gibson)': False, 'contains(captain)': False, 'contains(military)': False, 'contains(20)': False, 'contains(blair)': False, 'contains(nowhere)': False, 'contains(length)': False, 'contains(nicely)': False, 'contains(cause)': False, 'contains(pass)': False, 'contains(episode)': False, 'contains(kiss)': False, 'contains(arnold)': False, 'contains(please)': False, 'contains(hasn)': False, 'contains(phone)': False, 'contains(filmmaking)': False, 'contains(formula)': False, 'contains(boyfriend)': False, 'contains(talents)': False, 'contains(creating)': False, 'contains(kelly)': False, 'contains(buy)': False, 'contains(wide)': False, 'contains(fantasy)': False, 'contains(mood)': False, 'contains(heads)': False, 'contains(pathetic)': False, 'contains(lacks)': False, 'contains(loved)': False, 'contains(asked)': False, 'contains(mrs)': False, 'contains(witty)': False, 'contains(shakespeare)': False, 'contains(mulan)': False, 'contains(generation)': False, 'contains(affair)': False, 'contains(pieces)': False, 'contains(task)': False, 'contains(rare)': False, 'contains(kept)': False, 'contains(cameo)': False, 'contains(fascinating)': False, 'contains(ed)': False, 'contains(fbi)': False, 'contains(burton)': False, 'contains(incredible)': False, 'contains(accent)': False, 'contains(artist)': False, 'contains(superior)': False, 'contains(academy)': False, 'contains(thomas)': False, 'contains(spirit)': False, 'contains(technical)': False, 'contains(confusing)': False, 'contains(poorly)': False, 'contains(target)': True, 'contains(lover)': False, 'contains(woo)': False, 'contains(mentioned)': False, 'contains(theaters)': False, 'contains(plane)': False, 'contains(confused)': False, 'contains(dennis)': False, 'contains(rob)': False, 'contains(appropriate)': False, 'contains(christmas)': False, 'contains(considered)': False, 'contains(legend)': False, 'contains(shame)': False, 'contains(soul)': False, 'contains(matt)': False, 'contains(campbell)': False, 'contains(process)': False, 'contains(bottom)': False, 'contains(sitting)': False, 'contains(brain)': False, 'contains(creepy)': False, 'contains(13)': False, 'contains(forever)': False, 'contains(dude)': False, 'contains(crap)': False, 'contains(superb)': False, 'contains(speech)': False, 'contains(ice)': False, 'contains(journey)': False, 'contains(masterpiece)': True, 'contains(intriguing)': False, 'contains(names)': False, 'contains(pick)': False, 'contains(speaking)': False, 'contains(virtually)': False, 'contains(award)': False, 'contains(worthy)': False, 'contains(marriage)': False, 'contains(deliver)': False, 'contains(cash)': False, 'contains(magic)': False, 'contains(respect)': False, 'contains(product)': False, 'contains(necessary)': False, 'contains(suppose)': False, 'contains(silent)': False, 'contains(pointless)': True, 'contains(station)': False, 'contains(affleck)': False, 'contains(dimensional)': False, 'contains(charlie)': False, 'contains(allows)': False, 'contains(avoid)': False, 'contains(meant)': False, 'contains(cops)': False, 'contains(attitude)': False, 'contains(relationships)': False, 'contains(hits)': False, 'contains(stephen)': False, 'contains(spends)': False, 'contains(relief)': False, 'contains(physical)': False, 'contains(count)': False, 'contains(reviews)': False, 'contains(appreciate)': False, 'contains(cliches)': False, 'contains(holds)': False, 'contains(pure)': False, 'contains(plans)': False, 'contains(limited)': False, 'contains(failed)': False, 'contains(pain)': False, 'contains(impression)': False, 'contains(unless)': False, 'contains(sub)': False, 'contains([)': False, 'contains(total)': False, 'contains(creature)': False, 'contains(viewing)': False, 'contains(loves)': False, 'contains(princess)': False, 'contains(kate)': False, 'contains(rising)': False, 'contains(woods)': False, 'contains(baldwin)': False, 'contains(angry)': False, 'contains(drawn)': False, 'contains(step)': False, 'contains(matrix)': False, 'contains(themes)': False, 'contains(satire)': False, 'contains(arts)': False, 'contains(])': False, 'contains(remake)': False, 'contains(wall)': False, 'contains(moral)': False, 'contains(color)': False, 'contains(ray)': False, 'contains(stuck)': False, 'contains(touching)': False, 'contains(wit)': False, 'contains(tony)': False, 'contains(hanks)': False, 'contains(continues)': False, 'contains(damn)': False, 'contains(nobody)': False, 'contains(cartoon)': False, 'contains(keeping)': False, 'contains(realized)': False, 'contains(criminal)': False, 'contains(unfunny)': False, 'contains(comedic)': False, 'contains(martial)': False, 'contains(disappointing)': False, 'contains(anti)': False, 'contains(graphic)': False, 'contains(stunning)': False, 'contains(actions)': False, 'contains(floor)': False, 'contains(emotion)': False, 'contains(soldiers)': False, 'contains(edward)': False, 'contains(comedies)': False, 'contains(driver)': False, 'contains(expectations)': False, 'contains(added)': True, 'contains(mad)': False, 'contains(angels)': False, 'contains(shallow)': False, 'contains(suspect)': False, 'contains(humorous)': False, 'contains(phantom)': False, 'contains(appealing)': False, 'contains(device)': False, 'contains(design)': False, 'contains(industry)': False, 'contains(reach)': False, 'contains(fat)': False, 'contains(blame)': False, 'contains(united)': False, 'contains(sign)': False, 'contains(portrayal)': False, 'contains(rocky)': False, 'contains(finale)': False, 'contains(grand)': False, 'contains(opposite)': True, 'contains(hotel)': False, 'contains(match)': False, 'contains(damme)': False, 'contains(speed)': False, 'contains(ok)': False, 'contains(loving)': False, 'contains(field)': False, 'contains(larry)': False, 'contains(urban)': False, 'contains(troopers)': False, 'contains(compared)': False, 'contains(apes)': False, 'contains(rose)': False, 'contains(falling)': False, 'contains(era)': False, 'contains(loses)': False, 'contains(adults)': False, 'contains(managed)': False, 'contains(dad)': False, 'contains(therefore)': False, 'contains(pg)': False, 'contains(results)': True, 'contains(guns)': False, 'contains(radio)': False, 'contains(lady)': False, 'contains(manage)': False, 'contains(spice)': False, 'contains(naked)': False, 'contains(started)': False, 'contains(intense)': False, 'contains(humanity)': False, 'contains(wonderfully)': False, 'contains(slasher)': False, 'contains(bland)': False, 'contains(imagination)': False, 'contains(walking)': False, 'contains(willing)': False, 'contains(horse)': False, 'contains(rent)': False, 'contains(mix)': False, 'contains(generated)': False, 'contains(g)': False, 'contains(utterly)': False, 'contains(scientist)': False, 'contains(washington)': False, 'contains(notice)': False, 'contains(players)': False, 'contains(teenagers)': False, 'contains(moore)': False, 'contains(board)': False, 'contains(price)': False, 'contains(frightening)': False, 'contains(tommy)': False, 'contains(spectacular)': False, 'contains(bored)': False, 'contains(jane)': False, 'contains(join)': False, 'contains(producers)': True, 'contains(johnny)': False, 'contains(zero)': False, 'contains(vampires)': False, 'contains(adaptation)': False, 'contains(dollars)': False, 'contains(parody)': False, 'contains(documentary)': False, 'contains(dvd)': False, 'contains(wayne)': False, 'contains(post)': False, 'contains(exist)': False, 'contains(matters)': False, 'contains(chosen)': False, 'contains(mel)': False, 'contains(attractive)': False, 'contains(plain)': False, 'contains(trust)': False, 'contains(safe)': True, 'contains(reading)': False, 'contains(hoping)': False, 'contains(protagonist)': False, 'contains(feelings)': False, 'contains(fate)': False, 'contains(finding)': False, 'contains(feet)': False, 'contains(visuals)': False, 'contains(spawn)': False, 'contains(compelling)': False, 'contains(hall)': False, 'contains(sympathetic)': False, 'contains(featuring)': False, 'contains(difference)': False, 'contains(professional)': False, 'contains(drugs)': False, 'contains(ford)': False, 'contains(shooting)': False, 'contains(gold)': False, 'contains(patch)': False, 'contains(build)': False, 'contains(boat)': True, 'contains(cruise)': False, 'contains(honest)': False, 'contains(media)': False, 'contains(flicks)': False, 'contains(bug)': False, 'contains(bringing)': False, 'contains(dangerous)': False, 'contains(watched)': False, 'contains(grant)': False, 'contains(smile)': False, 'contains(plus)': False, 'contains(shouldn)': False, 'contains(decision)': False, 'contains(visually)': False, 'contains(allow)': False, 'contains(starship)': False, 'contains(roberts)': False, 'contains(dying)': False, 'contains(portrayed)': False, 'contains(turning)': False, 'contains(believes)': False, 'contains(changed)': False, 'contains(shock)': False, 'contains(destroy)': False, 'contains(30)': False, 'contains(crowd)': False, 'contains(broken)': False, 'contains(tired)': False, 'contains(fail)': False, 'contains(south)': False, 'contains(died)': False, 'contains(cult)': False, 'contains(fake)': False, 'contains(vincent)': False, 'contains(identity)': False, 'contains(sexy)': False, 'contains(hunt)': False, 'contains(jedi)': False, 'contains(flynt)': False, 'contains(alex)': False, 'contains(engaging)': False, 'contains(serve)': False, 'contains(snake)': False, 'contains(yeah)': False, 'contains(expecting)': True, 'contains(100)': False, 'contains(decade)': False, 'contains(ups)': False, 'contains(constant)': False, 'contains(current)': False, 'contains(survive)': False, 'contains(jimmy)': False, 'contains(buddy)': False, 'contains(send)': False, 'contains(brooks)': False, 'contains(goofy)': False, 'contains(likable)': False, 'contains(humour)': False, 'contains(technology)': False, 'contains(files)': False, 'contains(babe)': False, 'contains(aspects)': False, 'contains(presents)': False, 'contains(kills)': False, 'contains(supposedly)': False, 'contains(eight)': False, 'contains(sandler)': False, 'contains(hospital)': False, 'contains(test)': False, 'contains(hidden)': False, 'contains(brian)': False, 'contains(books)': False, 'contains(promise)': False, 'contains(determined)': False, 'contains(professor)': False, 'contains(welcome)': False, 'contains(pleasure)': False, 'contains(succeeds)': False, 'contains(individual)': False, 'contains(annie)': False, 'contains(mob)': False, 'contains(ted)': False, 'contains(virus)': False, 'contains(content)': False, 'contains(gary)': False, 'contains(direct)': False, 'contains(contrived)': False, 'contains(carpenter)': False, 'contains(scale)': False, 'contains(sick)': False, 'contains(nasty)': False, 'contains(conflict)': False, 'contains(haunting)': False, 'contains(ghost)': False, 'contains(filmmaker)': False, 'contains(japanese)': False, 'contains(helps)': False, 'contains(fare)': False, 'contains(lucky)': False, 'contains(ultimate)': False, 'contains(window)': False, 'contains(support)': False, 'contains(goal)': True, 'contains(provided)': False, 'contains(genius)': False, 'contains(winner)': False, 'contains(taylor)': False, 'contains(fantastic)': False, 'contains(faith)': False, 'contains(lynch)': False, 'contains(fit)': False, 'contains(catherine)': False, 'contains(ms)': False, 'contains(paced)': False, 'contains(breaks)': False, 'contains(al)': False, 'contains(frame)': False, 'contains(travel)': False, 'contains(badly)': False, 'contains(available)': False, 'contains(cares)': False, 'contains(reeves)': False, 'contains(crash)': False, 'contains(driving)': False, 'contains(press)': False, 'contains(seagal)': False, 'contains(amy)': False, 'contains(9)': False, 'contains(headed)': False, 'contains(instance)': False, 'contains(excuse)': False, 'contains(offensive)': False, 'contains(narrative)': False, 'contains(fault)': False, 'contains(bus)': False, 'contains(f)': False, 'contains(extreme)': False, 'contains(miller)': False, 'contains(guilty)': False, 'contains(grows)': False, 'contains(overly)': False, 'contains(liners)': False, 'contains(forgotten)': False, 'contains(ahead)': False, 'contains(accept)': False, 'contains(porn)': False, 'contains(directly)': False, 'contains(helen)': False, 'contains(began)': False, 'contains(lord)': False, 'contains(folks)': False, 'contains(mediocre)': False, 'contains(bar)': False, 'contains(surface)': False, 'contains(super)': False, 'contains(failure)': False, 'contains(6)': False, 'contains(acted)': False, 'contains(quiet)': False, 'contains(laughable)': False, 'contains(sheer)': False, 'contains(security)': True, 'contains(emotionally)': False, 'contains(season)': False, 'contains(stuart)': False, 'contains(jail)': False, 'contains(deals)': False, 'contains(cheesy)': False, 'contains(court)': False, 'contains(beach)': False, 'contains(austin)': False, 'contains(model)': False, 'contains(outstanding)': False, 'contains(substance)': False, 'contains(nudity)': False, 'contains(slapstick)': True, 'contains(joan)': False, 'contains(reveal)': False, 'contains(placed)': False, 'contains(check)': False, 'contains(beast)': False, 'contains(hurt)': False, 'contains(bloody)': False, 'contains(acts)': False, 'contains(fame)': False, 'contains(meeting)': False, 'contains(nuclear)': False, 'contains(1996)': False, 'contains(strength)': False, 'contains(center)': False, 'contains(funniest)': False, 'contains(standing)': False, 'contains(damon)': False, 'contains(clich)': False, 'contains(position)': False, 'contains(desire)': False, 'contains(driven)': False, 'contains(seat)': False, 'contains(stock)': False, 'contains(wondering)': False, 'contains(realizes)': False, 'contains(dealing)': False, 'contains(taste)': False, 'contains(routine)': False, 'contains(comparison)': False, 'contains(cinematographer)': False, 'contains(seconds)': False, 'contains(singing)': False, 'contains(gangster)': False, 'contains(responsible)': False, 'contains(football)': False, 'contains(remarkable)': False, 'contains(hunting)': False, 'contains(adams)': False, 'contains(fly)': False, 'contains(suspects)': False, 'contains(treat)': False, 'contains(hopes)': False, 'contains(heaven)': False, 'contains(myers)': False, 'contains(struggle)': False, 'contains(costumes)': False, 'contains(beat)': False, 'contains(happening)': False, 'contains(skills)': False, 'contains(ugly)': False, 'contains(figures)': False, 'contains(thoroughly)': False, 'contains(ill)': False, 'contains(surprises)': False, 'contains(player)': False, 'contains(rival)': False, 'contains(guard)': True, 'contains(anthony)': False, 'contains(strike)': False, 'contains(community)': False, 'contains(streets)': False, 'contains(hopkins)': False, 'contains(ended)': False, 'contains(originally)': False, 'contains(sarah)': False, 'contains(creative)': False, 'contains(characterization)': False, 'contains(thankfully)': False, 'contains(growing)': False, 'contains(sharp)': False, 'contains(williamson)': False, 'contains(eccentric)': False, 'contains(explained)': False, 'contains(hey)': False, 'contains(claire)': False, 'contains(steal)': False, 'contains(inevitable)': False, 'contains(joel)': False, 'contains(core)': False, 'contains(weren)': False, 'contains(sorry)': False, 'contains(built)': False, 'contains(anne)': False, 'contains(breaking)': False, 'contains(villains)': False, 'contains(critic)': False, 'contains(lets)': False, 'contains(visit)': False, 'contains(followed)': False}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 5.3 Train a Classifier",
   "id": "1174e180191f0038"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:53.384330Z",
     "start_time": "2025-04-23T18:25:51.011976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import classify, NaiveBayesClassifier\n",
    "\n",
    "# Create the feature sets\n",
    "feature_sets = [(document_features(d), c) for (d, c) in documents]\n",
    "\n",
    "# Train/test split\n",
    "train_set, test_set = feature_sets[:800], feature_sets[800:]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy:', classify.accuracy(classifier, test_set))"
   ],
   "id": "8dc035e69dbb4d9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133333333333334\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 5.4 Most Informative Features",
   "id": "af3d4d331de52fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:25:53.399100Z",
     "start_time": "2025-04-23T18:25:53.391819Z"
    }
   },
   "cell_type": "code",
   "source": "classifier.show_most_informative_features(10)",
   "id": "f8d49d2c1780a9c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(wonderfully) = True              pos : neg    =     10.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =      8.7 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      7.0 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      6.8 : 1.0\n",
      "       contains(patrick) = True              pos : neg    =      6.6 : 1.0\n",
      "         contains(waste) = True              neg : pos    =      6.5 : 1.0\n",
      "         contains(worst) = True              neg : pos    =      6.5 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      6.4 : 1.0\n",
      "      contains(godzilla) = True              neg : pos    =      6.4 : 1.0\n",
      "       contains(unfunny) = True              neg : pos    =      5.8 : 1.0\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß† How to Interpret This\n",
    "\n",
    "Each line tells you:\n",
    "- A specific **word** that appears in a review\n",
    "- Its predicted **sentiment direction** (positive or negative)\n",
    "- And a **ratio** showing how strongly it correlates with that sentiment\n",
    "\n",
    "---\n",
    "\n",
    "üîé Example Breakdown:\n",
    "- `contains(wonderfully) = True pos : neg = 10.9 : 1.0`\n",
    "    - ‚Üí If a review contains the word wonderfully, it is 10.9 times more likely to be positive than negative.\n",
    "    - üí¨ Interpretation: \"wonderfully\" is a strong indicator of a positive review.\n",
    "- `contains(awful) = True neg : pos = 7.0 : 1.0`\n",
    "    - ‚Üí If a review contains awful, it‚Äôs 7x more likely to be negative.\n",
    "    - üí¨ \"awful\" is clearly associated with negative reviews.\n",
    "- `contains(damon) = True pos : neg = 6.8 : 1.0`\n",
    "    - ‚Üí \"damon\" appears more often in positive reviews ‚Äî maybe because reviewers like Matt Damon!\n",
    "- `contains(godzilla) = True neg : pos = 6.4 : 1.0`\n",
    "    - ‚Üí In this dataset, \"godzilla\" is more often mentioned in negative reviews. (Maybe the movie was bad üôÉ)"
   ],
   "id": "15d3c7e41f29b775"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚ö†Ô∏è Notes\n",
    "- These are not causal relationships ‚Äî just correlations from the training data.\n",
    "- The features are based on word presence only (contains(word) = True), so no context or syntax is considered.\n",
    "- Words like ‚Äòpatrick‚Äô, ‚Äòdamon‚Äô, or ‚Äògodzilla‚Äô could be highly dataset-specific.\n",
    "- This is a very basic method and doesn‚Äôt handle word order, syntax, or semantics. In real NLP systems, deep learning models (e.g., BERT) are typically used."
   ],
   "id": "322f0df2c40c7936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üîö Part 6: Summary\n",
    "\n",
    "Now that we‚Äôve explored NLTK, it‚Äôs helpful to summarize what it‚Äôs good for and where other tools like spaCy might offer advantages."
   ],
   "id": "157368bbbdd9d423"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úÖ What We've Learned in This NLTK Section:\n",
    "\n",
    "| Topic                   | What We Did                                                                       |\n",
    "|-------------------------|-----------------------------------------------------------------------------------|\n",
    "| **Tokenization**        | Split text into words and sentences using `word_tokenize()` and `sent_tokenize()` |\n",
    "| **Stopword Removal**    | Removed common words using `nltk.corpus.stopwords`                                |\n",
    "| **Stemming**            | Reduced words to their root using `PorterStemmer`                                 |\n",
    "| **Lemmatization**       | Reduced words to dictionary form using `WordNetLemmatizer`                        |\n",
    "| **POS Tagging**         | Labeled each word with its part of speech using `pos_tag()`                       |\n",
    "| **NER**                 | Identified named entities with `ne_chunk()`                                       |\n",
    "| **Text Classification** | Built a Naive Bayes classifier using word features                                |\n"
   ],
   "id": "4bed9142e1b93da9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß™ Part 7: Exercises\n",
    "\n",
    "These exercises help you apply the concepts you've learned in this notebook."
   ],
   "id": "f24c3e6c09219fc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîπ 7.1 Write `preprocess`",
   "id": "c9c1ecfc5c58f2df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:19.474358Z",
     "start_time": "2025-04-23T21:32:18.878188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STEMMER = PorterStemmer()\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "\n",
    "\n",
    "def preprocess_nltk(text: str, use_lemmatizer: bool = True) -> list[str]:\n",
    "    \"\"\"\n",
    "    1. Tokenize text into words.\n",
    "    2. Remove punctuation tokens.\n",
    "    3. Remove stopwords and non-alphabetic tokens.\n",
    "    4. POS-tag and keep only NOUN, VERB, ADJ, ADV.\n",
    "    5. Lemmatize (or stem) and lowercase.\n",
    "    \"\"\"\n",
    "    # yor code here\n",
    "    pass"
   ],
   "id": "6e5d3ac48a35ba23",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:19.480020Z",
     "start_time": "2025-04-23T21:32:19.478271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Hello, world! The quick (brown) foxes‚Äîare jumping happily over lazy dogs.\"\n",
    "print('Lemmatized:', preprocess_nltk(text, use_lemmatizer=True))\n",
    "print('Stemmed:   ', preprocess_nltk(text, use_lemmatizer=False))\n",
    "# Expected:\n",
    "# Lemmatized: ['world', 'quick', 'jumping', 'happily', 'lazy', 'dog']\n",
    "# Stemmed:    ['world', 'quick', 'jump', 'happili', 'lazi', 'dog']"
   ],
   "id": "260e2a8aef0b3783",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized: None\n",
      "Stemmed:    None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ‚úÖ Answer",
   "id": "d02a90907b1e9345"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:22.229398Z",
     "start_time": "2025-04-23T21:32:22.224385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STEMMER = PorterStemmer()\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "\n",
    "\n",
    "def preprocess_nltk(text: str, use_lemmatizer: bool = True) -> list[str]:\n",
    "    \"\"\"\n",
    "    1. Tokenize text into words.\n",
    "    2. Remove punctuation tokens.\n",
    "    3. Remove stopwords and non-alphabetic tokens.\n",
    "    4. POS-tag and keep only NOUN, VERB, ADJ, ADV.\n",
    "    5. Lemmatize (or stem) and lowercase.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 2. Remove pure punctuation tokens\n",
    "    tokens = [t for t in tokens if t not in PUNCTUATION]\n",
    "\n",
    "    # 3. Filter out non-alpha and stopwords\n",
    "    tokens = [t for t in tokens if t.isalpha() and t.lower() not in STOPWORDS]\n",
    "\n",
    "    # 4. POS-tag and filter by allowed tags\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    allowed = {\n",
    "        'NN', 'NNS',\n",
    "        'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',\n",
    "        'JJ', 'JJR', 'JJS',\n",
    "        'RB', 'RBR', 'RBS'\n",
    "    }\n",
    "    tokens = [word for word, tag in tagged if tag in allowed]\n",
    "\n",
    "    # 5. Normalize\n",
    "    if use_lemmatizer:\n",
    "        tokens = [LEMMATIZER.lemmatize(t) for t in tokens]\n",
    "    else:\n",
    "        tokens = [STEMMER.stem(t) for t in tokens]\n",
    "\n",
    "    # Lowercase\n",
    "    return [t.lower() for t in tokens]"
   ],
   "id": "5799ecaf60c3cab7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:23.049815Z",
     "start_time": "2025-04-23T21:32:22.993022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Hello, world! The quick (brown) foxes‚Äîare jumping happily over lazy dogs.\"\n",
    "print('Lemmatized:', preprocess_nltk(text, use_lemmatizer=True))\n",
    "print('Stemmed:   ', preprocess_nltk(text, use_lemmatizer=False))"
   ],
   "id": "7e5ac6724a8b814e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHello, world! The quick (brown) foxes‚Äîare jumping happily over lazy dogs.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLemmatized:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[43mpreprocess_nltk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_lemmatizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStemmed:   \u001B[39m\u001B[38;5;124m'\u001B[39m, preprocess_nltk(text, use_lemmatizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m))\n",
      "Cell \u001B[0;32mIn[4], line 29\u001B[0m, in \u001B[0;36mpreprocess_nltk\u001B[0;34m(text, use_lemmatizer)\u001B[0m\n\u001B[1;32m     26\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tokens \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39misalpha() \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m STOPWORDS]\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# 4. POS-tag and filter by allowed tags\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m tagged \u001B[38;5;241m=\u001B[39m \u001B[43mnltk\u001B[49m\u001B[38;5;241m.\u001B[39mpos_tag(tokens)\n\u001B[1;32m     30\u001B[0m allowed \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNNS\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBD\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBG\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBZ\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJ\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJS\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRBR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRBS\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     35\u001B[0m }\n\u001B[1;32m     36\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word, tag \u001B[38;5;129;01min\u001B[39;00m tagged \u001B[38;5;28;01mif\u001B[39;00m tag \u001B[38;5;129;01min\u001B[39;00m allowed]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 7.2 Create an NLTK ‚ÄúPipeline‚Äù Wrapper\n",
    "If you want to apply this to many documents, wrap it in a simple class:"
   ],
   "id": "4f6d55e58de6fd39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:23.946716Z",
     "start_time": "2025-04-23T21:32:23.929669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NLTKPreprocessor:\n",
    "    def __init__(self, use_lemmatizer: bool = True):\n",
    "        self.use_lemmatizer = use_lemmatizer\n",
    "\n",
    "    def __call__(self, text: str) -> list[str]:\n",
    "        return preprocess_nltk(text, self.use_lemmatizer)\n",
    "\n",
    "\n",
    "# Instantiate and test\n",
    "pp = NLTKPreprocessor(use_lemmatizer=True)\n",
    "print(pp(\"NLTK pipelines can be neatly organized into functions.\"))"
   ],
   "id": "df7af70981e98433",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Instantiate and test\u001B[39;00m\n\u001B[1;32m     10\u001B[0m pp \u001B[38;5;241m=\u001B[39m NLTKPreprocessor(use_lemmatizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mpp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNLTK pipelines can be neatly organized into functions.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[6], line 6\u001B[0m, in \u001B[0;36mNLTKPreprocessor.__call__\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpreprocess_nltk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_lemmatizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[4], line 29\u001B[0m, in \u001B[0;36mpreprocess_nltk\u001B[0;34m(text, use_lemmatizer)\u001B[0m\n\u001B[1;32m     26\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tokens \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39misalpha() \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m STOPWORDS]\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# 4. POS-tag and filter by allowed tags\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m tagged \u001B[38;5;241m=\u001B[39m \u001B[43mnltk\u001B[49m\u001B[38;5;241m.\u001B[39mpos_tag(tokens)\n\u001B[1;32m     30\u001B[0m allowed \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNNS\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBD\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBG\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVBZ\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJ\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJJS\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRBR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRBS\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     35\u001B[0m }\n\u001B[1;32m     36\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word, tag \u001B[38;5;129;01min\u001B[39;00m tagged \u001B[38;5;28;01mif\u001B[39;00m tag \u001B[38;5;129;01min\u001B[39;00m allowed]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîπ 7.3 Performance Comparison\n",
    "Measure how long it takes to preprocess a batch of texts with vs. without lemmatization:"
   ],
   "id": "f132ff79a5df6d1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:32:37.466673Z",
     "start_time": "2025-04-23T21:32:33.286918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "docs = [\n",
    "    \"Natural Language Processing with NLTK is fun.\" * 50\n",
    "    for _ in range(500)\n",
    "]\n",
    "\n",
    "\n",
    "def time_it(pp, docs):\n",
    "    start = time.perf_counter()\n",
    "    [pp(d) for d in docs]\n",
    "    return time.perf_counter() - start\n",
    "\n",
    "\n",
    "pp_lemma = NLTKPreprocessor(use_lemmatizer=True)\n",
    "pp_stem = NLTKPreprocessor(use_lemmatizer=False)\n",
    "\n",
    "t_lemma = time_it(pp_lemma, docs)\n",
    "t_stem = time_it(pp_stem, docs)\n",
    "\n",
    "print(f'Lemmatizer time: {t_lemma:.2f}s')\n",
    "print(f'Stemmer time:    {t_stem:.2f}s')"
   ],
   "id": "b0e01a406d2e37e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizer time: 2.59s\n",
      "Stemmer time:    1.59s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c75f58041061e7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
