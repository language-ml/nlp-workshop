{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<img src='https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png' width=150 height=150> <br>\n",
    "<font color=0F5298 size=6>\n",
    "Natural Language Processing<br>\n",
    "<font color=2565AE size=4>\n",
    "Computer Engineering Department<br>\n",
    "Spring 2025<br>\n",
    "<font color=3C99D size=4>\n",
    "Workshop 1 - NLP Frameworks - Parsivar<br>\n",
    "<font color=696880 size=3>\n",
    "<a href='https://language.ml'>https://language.ml</a><br>\n",
    "info [AT] language [dot] ml"
   ],
   "id": "99ace3b6f559ac3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 📖 Part 1: Introduction\n",
    "\n",
    "## ❓ What is Parsivar? ([GitHub](https://github.com/ICTRC/Parsivar))\n",
    "\n",
    "**Parsivar** is an open-source Python library built specifically for **Persian (Farsi) NLP**.\n",
    "It offers ready-made components for:\n",
    "\n",
    "- **Normalization** and orthographic fixes\n",
    "- **Sentence / word tokenization**\n",
    "- **Stemming** (rule-based)\n",
    "- **Part-of-speech tagging** (HMM/Wapiti)\n",
    "- **Dependency parsing** (UD-style)\n",
    "- **Spell checking / autocorrection**\n",
    "\n",
    "*(Parsivar does **not** ship a lemmatizer or NER in its current release.)*\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ When to Use Parsivar\n",
    "\n",
    "- You need a **quick, self-contained Persian NLP** pipeline in pure Python.\n",
    "- You want features **not bundled in Hazm** (e.g. built-in NER, sentiment).\n",
    "- You prefer **rule + ML hybrids** instead of heavier deep-learning models.\n",
    "- You’re preprocessing Persian text for classical ML or linguistic analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚫 When Not to Use Parsivar\n",
    "\n",
    "- You need **transformer-based** embeddings or state-of-the-art accuracy (use 🤗 Hugging Face models).\n",
    "- You require **dependency parsing** (Parsivar doesn’t provide one).\n",
    "- You’re building **multilingual** pipelines (Parsivar is Persian-only).\n",
    "- You need **industrial throughput**—for very large-scale, spaCy with custom Persian models is faster."
   ],
   "id": "98dacdc744a17d41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ⚙️ Installation & Setup",
   "id": "2da01515538c4e99"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T21:44:23.333911Z",
     "start_time": "2025-04-23T21:44:11.595948Z"
    }
   },
   "source": "!pip install parsivar",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parsivar\r\n",
      "  Downloading parsivar-0.2.3.1-py3-none-any.whl.metadata (242 bytes)\r\n",
      "Requirement already satisfied: nltk>=3.6.6 in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from parsivar) (3.9.1)\r\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk>=3.6.6->parsivar) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk>=3.6.6->parsivar) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk>=3.6.6->parsivar) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from nltk>=3.6.6->parsivar) (4.67.1)\r\n",
      "Downloading parsivar-0.2.3.1-py3-none-any.whl (18.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.0/18.0 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hInstalling collected packages: parsivar\r\n",
      "Successfully installed parsivar-0.2.3.1\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 💡 Part 2: Preprocessing\n",
    "\n",
    "We’ll start by **normalizing** raw Persian text and then splitting it into **sentences** and **words** with Parsivar."
   ],
   "id": "d156592c874c2fa6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 📦 Imports",
   "id": "5ccedc8187926827"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:56:21.140019Z",
     "start_time": "2025-04-23T21:56:21.137846Z"
    }
   },
   "cell_type": "code",
   "source": "from parsivar import Normalizer, Tokenizer",
   "id": "3e21595536fe0df8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 2.1 Normalization",
   "id": "e56ca2a21886596d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:24.787807Z",
     "start_time": "2025-04-23T22:26:24.784298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"به گزارش ایسنا سمینارها ی شیمی آلی از امروز ۱۱ شهریور ۱۳۹۶ در دانشگاه علم و صنعت ایران آغاز به کار کردند. این سمینار تا ۱۳ شهریور ادامه می یابد.\"\n",
    "normalizer = Normalizer()\n",
    "print(normalizer.normalize(text))"
   ],
   "id": "50fb6c95b887c972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش ایسنا سمینارها ی شیمی آلی از امروز 11 شهریور 1396 در دانشگاه علم و صنعت ایران آغاز به کار کردند . این سمینار تا 13 شهریور ادامه می‌یابد .\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:26.950303Z",
     "start_time": "2025-04-23T22:26:26.920543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalizer = Normalizer(statistical_space_correction=True)\n",
    "print(normalizer.normalize(text))"
   ],
   "id": "6faac56f35291f93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش ایسنا سمینارها‌ی شیمی آلی از امروز 11 شهریور 1396 در دانشگاه علم و صنعت ایران آغاز به کار کردند . این سمینار تا 13 شهریور ادامه می‌یابد . \n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:28.844612Z",
     "start_time": "2025-04-23T22:26:28.826739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalizer = Normalizer(date_normalizing_needed=True)\n",
    "print(normalizer.normalize(text))"
   ],
   "id": "95be8298bb60aa26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش ایسنا سمینارها ی شیمی آلی از امروز y1396m6d11 در دانشگاه علم و صنعت ایران آغاز به کار کردند . این سمینار تا y0m6d13 ادامه می‌یابد .\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:29.224591Z",
     "start_time": "2025-04-23T22:26:29.206451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalizer = Normalizer(pinglish_conversion_needed=True)\n",
    "print(normalizer.normalize(\"farda asman abri ast.\"))"
   ],
   "id": "bb225b9c557e7e5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فردا اسمان ابری است .\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 2.2 Sentence Tokenization",
   "id": "fa397620c870e8b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:34.318606Z",
     "start_time": "2025-04-23T22:26:34.313165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer()\n",
    "normalizer = Normalizer()\n",
    "sentences = tokenizer.tokenize_sentences(normalizer.normalize(text))\n",
    "\n",
    "for sent in sentences:\n",
    "    print(sent)"
   ],
   "id": "a7398b1f4bf5effc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش ایسنا سمینارها ی شیمی آلی از امروز 11 شهریور 1396 در دانشگاه علم و صنعت ایران آغاز به کار کردند  .\n",
      " این سمینار تا 13 شهریور ادامه می‌یابد  .\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 2.3 Word Tokenization",
   "id": "a35897298e966687"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:35.674762Z",
     "start_time": "2025-04-23T22:26:35.671619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sent in sentences:\n",
    "    words = tokenizer.tokenize_words(normalizer.normalize(sent))\n",
    "    print(words)"
   ],
   "id": "d911d6181ca1a442",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['به', 'گزارش', 'ایسنا', 'سمینارها', 'ی', 'شیمی', 'آلی', 'از', 'امروز', '11', 'شهریور', '1396', 'در', 'دانشگاه', 'علم', 'و', 'صنعت', 'ایران', 'آغاز', 'به', 'کار', 'کردند', '.']\n",
      "['این', 'سمینار', 'تا', '13', 'شهریور', 'ادامه', 'می\\u200cیابد', '.']\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 🧠 Part 3: Morphology — Stemming\n",
    "\n",
    "Parsivar provides a rule-based **stemmer** but **does not** include a lemmatizer.\n",
    "\n",
    "If you need full lemmatization you’ll have to integrate another tool (e.g. Hazm’s `Lemmatizer`)."
   ],
   "id": "c876a86eea65177c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 📦 Imports",
   "id": "87363392a2379e02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:56:42.322959Z",
     "start_time": "2025-04-23T21:56:42.320954Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": "from parsivar import FindStems, Tokenizer",
   "id": "d6eba4a69f110b54",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 3.1 Stemming",
   "id": "8a6be2a97d0ce506"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:26:59.864359Z",
     "start_time": "2025-04-23T22:26:59.858041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stemmer = FindStems()\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "sentence = 'کتاب‌های جدیدم را به دوستان خوبم نشان دادم.'\n",
    "tokens = tokenizer.tokenize_words(sentence)\n",
    "\n",
    "stems = [stemmer.convert_to_stem(t) for t in tokens]\n",
    "print(tokens)\n",
    "print(stems)"
   ],
   "id": "83df020bdb4ef95d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['کتاب\\u200cهای', 'جدیدم', 'را', 'به', 'دوستان', 'خوبم', 'نشان', 'دادم.']\n",
      "['کتاب', 'جدید', 'را', 'به', 'دوست', 'خوب', 'نشان', 'دادم.']\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ✍️ Part 4: POS Tagging & Chunking",
   "id": "487e6974cccbdf40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 📦 Imports\n",
    "\n",
    "Parsivar’s HMM‐based POS tagger uses the **Wapiti** library under the hood. Before you run the tagger, install both Parsivar and its Wapiti binding."
   ],
   "id": "49f8e6c56bb6e6aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:00:02.978353Z",
     "start_time": "2025-04-23T21:59:57.433815Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install libwapiti",
   "id": "47c5fe6cf8e47ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libwapiti\r\n",
      "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: six in /opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages (from libwapiti) (1.17.0)\r\n",
      "Building wheels for collected packages: libwapiti\r\n",
      "  Building wheel for libwapiti (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp310-cp310-macosx_11_0_arm64.whl size=49039 sha256=6d4d50bf5d5f716bde41e58399bb2506bc54152c3a911c822257ba8ecd035392\r\n",
      "  Stored in directory: /Users/AmirMohammad/Library/Caches/pip/wheels/9f/cb/30/fef48ecac051e433987eccdb5682900b4c00d44a4bcd4d4ec8\r\n",
      "Successfully built libwapiti\r\n",
      "Installing collected packages: libwapiti\r\n",
      "Successfully installed libwapiti-0.2.1\r\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:09:01.701931Z",
     "start_time": "2025-04-23T22:09:01.700013Z"
    }
   },
   "cell_type": "code",
   "source": "from parsivar import Tokenizer, POSTagger, FindChunks",
   "id": "7ddb67aa86227d65",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 4.1 Tokenization & POS Tagging",
   "id": "261d9f1268b61d6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:04:23.655301Z",
     "start_time": "2025-04-23T22:04:23.378889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate tokenizer and tagger (use \"wapiti\" or \"stanford\")\n",
    "tokenizer = Tokenizer()\n",
    "tagger = POSTagger(tagging_model=\"wapiti\")\n",
    "\n",
    "sentence = 'من دوست دارم زبان فارسی را بهتر یاد بگیرم.'\n",
    "\n",
    "tokens = tokenizer.tokenize_words(sentence)\n",
    "tags = tagger.parse(tokens)\n",
    "\n",
    "tags"
   ],
   "id": "92ef6a86b2e1ea02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('من', 'PRO'),\n",
       " ('دوست', 'N_SING'),\n",
       " ('دارم', 'V_PRS'),\n",
       " ('زبان', 'N_SING'),\n",
       " ('فارسی', 'ADJ'),\n",
       " ('را', 'CLITIC'),\n",
       " ('بهتر', 'ADJ_CMPR'),\n",
       " ('یاد', 'N_SING'),\n",
       " ('بگیرم.', 'V_SUB')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 📋 Parsivar POS Tagset Reference\n",
    "\n",
    "| Tag      | Category     | Meaning                |\n",
    "|----------|--------------|------------------------|\n",
    "| N_SING   | Noun         | Singular noun          |\n",
    "| N_PLUR   | Noun         | Plural noun            |\n",
    "| V_PRS    | Verb         | Present-tense verb     |\n",
    "| V_PST    | Verb         | Past-tense verb        |\n",
    "| V_IMP    | Verb         | Imperative verb        |\n",
    "| ADJ      | Adjective    | Adjective              |\n",
    "| ADV      | Adverb       | Adverb                 |\n",
    "| PRON     | Pronoun      | Pronoun                |\n",
    "| DET      | Determiner   | Determiner             |\n",
    "| NUM      | Numeral      | Numeral                |\n",
    "| PREP     | Preposition  | Preposition            |\n",
    "| CONJ     | Conjunction  | Conjunction            |\n",
    "| PUNC     | Punctuation  | Punctuation mark       |"
   ],
   "id": "c06632fbfb698258"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 4.2 Phrase Chunking",
   "id": "e8ff7701b13cc4ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:08:22.484939Z",
     "start_time": "2025-04-23T23:08:22.481715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunker = FindChunks()\n",
    "chunk_tree = chunker.chunk_sentence(tags)"
   ],
   "id": "5ea5b4fd3af5f7e4",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:08:56.456853Z",
     "start_time": "2025-04-23T23:08:56.454401Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunk_tree)",
   "id": "b8b3441b9d249023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  من/PRO\n",
      "  (VP (VP دوست/N_SING دارم/V_PRS))\n",
      "  (NP زبان/N_SING فارسی/ADJ)\n",
      "  را/CLITIC\n",
      "  بهتر/ADJ_CMPR\n",
      "  (VP (VP یاد/N_SING بگیرم./V_SUB)))\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:09:00.143341Z",
     "start_time": "2025-04-23T23:09:00.141015Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunker.convert_nestedtree2rawstring(chunk_tree))",
   "id": "fbda5df643255374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "من [دوست دارم VP] [زبان فارسی NP] را بهتر [یاد بگیرم. VP]\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> `NP` denotes noun phrases, `VP` verb phrases, giving you easy access to phrase-level units for further analysis.",
   "id": "ce5122cb47c7fb37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 🌳 Part 5: Dependency Parsing",
   "id": "e7bc2312c75c4215"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 📦 Imports",
   "id": "5ad3be721ba8816c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:30:22.695308Z",
     "start_time": "2025-04-23T22:30:22.693429Z"
    }
   },
   "cell_type": "code",
   "source": "from parsivar import Tokenizer, DependencyParser",
   "id": "392aa5b12d1bb05a",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 5.1 Parse Sentences",
   "id": "4cef2862afa5e441"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:32:43.680804Z",
     "start_time": "2025-04-23T22:32:42.729701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer()\n",
    "parser = DependencyParser()\n",
    "\n",
    "text = \"به گزارش ایسنا سمینارها ی شیمی آلی از امروز ۱۱ شهریور ۱۳۹۶ در دانشگاه علم و صنعت ایران آغاز به کار کردند. این سمینار تا ۱۳ شهریور ادامه می یابد.\"\n",
    "\n",
    "sentences = tokenizer.tokenize_sentences(text)\n",
    "parsed_graphs = parser.parse_sents(sentences)\n",
    "\n",
    "for g in parsed_graphs:\n",
    "    print(g.tree())"
   ],
   "id": "a3e43be2c08aa76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(کردند\n",
      "  (به (گزارش (ایسنا (سمینارها (ی (شیمی آلی))))))\n",
      "  (از امروز)\n",
      "  (شهریور ۱۱)\n",
      "  (دانشگاه (در ۱۳۹۶) (علم (و (صنعت ایران))))\n",
      "  آغاز\n",
      "  (به کار)\n",
      "  .)\n",
      "(یابد (سمینار این) (تا (شهریور ۱۳)) ادامه می .)\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 🛠️ Part 6: Spell Correction",
   "id": "9c032affa30edf0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 📦 Imports",
   "id": "81db6f055404d077"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:33:43.111287Z",
     "start_time": "2025-04-23T22:33:43.108625Z"
    }
   },
   "cell_type": "code",
   "source": "from parsivar import SpellCheck",
   "id": "7b15923ef351a8c8",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 🔹 6.1 Correct Misspellings and Spacing\n",
    "\n",
    "To use the spell checker module download it's resources from [here](https://www.dropbox.com/s/tlyvnzv1ha9y1kl/spell.zip?dl=0) and after extraction copy the `spell/` directory to `parsivar/resource` -><br>\n",
    "`FileNotFoundError: [Errno 2] No such file or directory: '/opt/homebrew/anaconda3/envs/Jupyter310/lib/python3.10/site-packages/parsivar/resource/spell/mybigram_lm.pckl'`"
   ],
   "id": "6091f04a64d180ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T22:42:16.205329Z",
     "start_time": "2025-04-23T22:42:14.888543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spell = SpellCheck()\n",
    "\n",
    "bad_sentence = \"نمازگذاران وارد مسلی شدند.\"\n",
    "fixed_sentence = spell.spell_corrector(bad_sentence)\n",
    "\n",
    "print(bad_sentence)\n",
    "print(fixed_sentence)"
   ],
   "id": "601126b664ec391e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نمازگذاران وارد مسلی شدند.\n",
      "نمازگزاران وارد مصلی شدند .\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 🔚 Part 7: Summary & Comparison (Parsivar vs. Hazm)\n",
    "\n",
    "| Feature / Task               | **Hazm**                                          | **Parsivar**                                        |\n",
    "|------------------------------|---------------------------------------------------|-----------------------------------------------------|\n",
    "| **Normalization**            | ✔ Extensive, configurable                         | ✔ Good, statistical space correction                |\n",
    "| **Spell Correction**         | ✖                                                 | ✔ `SpellCheck` (needs LM files)                     |\n",
    "| **Sentence Tokenizer**       | ✔ `sent_tokenize`                                 | ✔ `Tokenizer.tokenize_sentences`                    |\n",
    "| **Word Tokenizer**           | ✔ `word_tokenize`                                 | ✔ `Tokenizer.tokenize_words`                        |\n",
    "| **Stemming**                 | ✔ `Stemmer`                                       | ✔ `FindStems`                                       |\n",
    "| **Lemmatization**            | ✔ `Lemmatizer`                                    | ✖ (not included)                                    |\n",
    "| **POS Tagging**              | ✔ Bijankhan tagger                                | ✔ HMM/Wapiti tagger                                 |\n",
    "| **Chunker**                  | ✔ `Chunker(model='chunker.model')`                | ✔ `FindChunks`                                      |\n",
    "| **Dependency Parsing**       | ✔ MaltParser wrapper (needs Java)                 | ✔ Pure-Python UD parser                             |\n",
    "| **Word/Sent Embeddings**     | ✔ `WordEmbedding` (fastText / word2vec, etc.)     | ✖                                                   |\n",
    "| **Named-Entity Recognition** | Optional (works if you supply a trained model)    | ✖ (no built-in support)                             |\n",
    "| **Installation weight**      | Light (Python + optional Java)                    | Light (Python + optional Wapiti)                    |\n",
    "| **Best for …**               | Rich morphology, chunking, embeddings, custom NER | Quick normalization + spell-fix + Java-free parsing |"
   ],
   "id": "a17e3009f66b4c22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Hazm** now covers **chunking** and **word/sentence embeddings** (fastText/word2vec).\n",
    "  It can also run NER **if you point it to a trained model**, but ships none by default.\n",
    "- **Parsivar** offers built-in **spell correction**, a pure-Python dependency parser, and chunking, but **no lemmatizer, embeddings, or NER**.\n",
    "- Choose **Hazm** for deeper linguistic pipelines (lemmas, embeddings, chunker, optional NER).\n",
    "- Choose **Parsivar** when you need fast spell-correction and a Java-free dependency parser, accepting the absence of lemmatizer/embeddings/NER."
   ],
   "id": "861daac821f708bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 🧪 Part 8: Integrated Pre-processing Pipeline (Parsivar Style)\n",
    "\n",
    "You’ll create a **`preprocess_parsivar`** function, wrap it in a class, and compare speed with spell-correction ON vs. OFF."
   ],
   "id": "fa60c056099f546c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 📦 Imports (local to this part)",
   "id": "af365c5fc91afdf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:27:44.662009Z",
     "start_time": "2025-04-24T00:27:44.660287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from parsivar import SpellCheck, Normalizer, Tokenizer, FindStems\n",
    "import string, time"
   ],
   "id": "88802018cdb0579b",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 8.1 preprocess_parsivar Function",
   "id": "9471153d5a15257f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:29:44.296233Z",
     "start_time": "2025-04-24T00:29:43.051060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spell = SpellCheck()\n",
    "normalizer = Normalizer(statistical_space_correction=True)\n",
    "tokenizer = Tokenizer()\n",
    "stemmer = FindStems()\n",
    "PUNCT = set(string.punctuation + '؟،؛«»…')\n",
    "\n",
    "\n",
    "def preprocess_parsivar(\n",
    "        text: str,\n",
    "        fix_spelling: bool = True,\n",
    "        use_stemmer: bool = False\n",
    ") -> list[str]:\n",
    "    \"\"\"Return a list of clean (optionally stemmed) tokens.\"\"\"\n",
    "    # your code here\n",
    "    pass"
   ],
   "id": "dd20906be4e4090d",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:29:46.107891Z",
     "start_time": "2025-04-24T00:29:46.105360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = \"نمازگذاران وارد مسلی شدند.\"\n",
    "print(preprocess_parsivar(sample))\n",
    "# Expected:\n",
    "# ['نمازگزاران', 'وارد', 'مصلی', 'شدند']"
   ],
   "id": "fb0e844bdd4a9a49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ✅ Answer",
   "id": "3cc8d96ba1cc418e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:29:52.494398Z",
     "start_time": "2025-04-24T00:29:51.168744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spell = SpellCheck()\n",
    "normalizer = Normalizer(statistical_space_correction=True)\n",
    "tokenizer = Tokenizer()\n",
    "stemmer = FindStems()\n",
    "PUNCT = set(string.punctuation + '؟،؛«»…')\n",
    "\n",
    "\n",
    "def preprocess_parsivar(\n",
    "        text: str,\n",
    "        fix_spelling: bool = True,\n",
    "        use_stemmer: bool = False\n",
    ") -> list[str]:\n",
    "    \"\"\"Return a list of clean (optionally stemmed) tokens.\"\"\"\n",
    "    if fix_spelling:\n",
    "        text = spell.spell_corrector(text)\n",
    "    text = normalizer.normalize(text)\n",
    "\n",
    "    tokens = []\n",
    "    for sent in tokenizer.tokenize_sentences(text):\n",
    "        for tok in tokenizer.tokenize_words(sent):\n",
    "            if tok in PUNCT:\n",
    "                continue\n",
    "            tokens.append(tok)\n",
    "\n",
    "    if use_stemmer:\n",
    "        tokens = [stemmer.convert_to_stem(t) for t in tokens]\n",
    "\n",
    "    return [t.lower() for t in tokens]"
   ],
   "id": "df1afa6c02fa5f75",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:29:52.500823Z",
     "start_time": "2025-04-24T00:29:52.496874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = \"نمازگذاران وارد مسلی شدند.\"\n",
    "print(preprocess_parsivar(sample))"
   ],
   "id": "cff216a32d6f82a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['نمازگزاران', 'وارد', 'مصلی', 'شدند']\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 8.2 ParsivarPreprocessor Class",
   "id": "f3b20cf90797886e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:30:13.785877Z",
     "start_time": "2025-04-24T00:30:13.782916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ParsivarPreprocessor:\n",
    "    def __init__(self, fix_spelling=True, use_stemmer=False):\n",
    "        self.fix_spelling = fix_spelling\n",
    "        self.use_stemmer = use_stemmer\n",
    "\n",
    "    def __call__(self, text: str) -> list[str]:\n",
    "        return preprocess_parsivar(\n",
    "            text,\n",
    "            fix_spelling=self.fix_spelling,\n",
    "            use_stemmer=self.use_stemmer\n",
    "        )\n",
    "\n",
    "    def batch(self, docs):\n",
    "        return [self(d) for d in docs]"
   ],
   "id": "aa7397664f69cd0c",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:30:14.309361Z",
     "start_time": "2025-04-24T00:30:14.302150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pp = ParsivarPreprocessor(fix_spelling=True, use_stemmer=True)\n",
    "print(pp(\"کتاب های جدیدم را خوانده ام .\"))"
   ],
   "id": "cd23db1c5e50f3f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['کتاب', 'جدید', 'را', 'خواند&خوان']\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🔹 8.3 Speed Comparison",
   "id": "8efe1a5102f70a5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:30:17.516706Z",
     "start_time": "2025-04-24T00:30:16.856148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = [sample] * 500  # duplicate sample 500×\n",
    "\n",
    "\n",
    "def time_it(prep, docs):\n",
    "    start = time.perf_counter()\n",
    "    _ = prep.batch(docs)\n",
    "    return time.perf_counter() - start\n",
    "\n",
    "\n",
    "pp_spell = ParsivarPreprocessor(fix_spelling=True, use_stemmer=False)\n",
    "pp_raw = ParsivarPreprocessor(fix_spelling=False, use_stemmer=False)\n",
    "\n",
    "t_spell = time_it(pp_spell, docs)\n",
    "t_raw = time_it(pp_raw, docs)\n",
    "\n",
    "print(f\"With spell-correction : {t_spell:.3f}s\")\n",
    "print(f\"Without correction    : {t_raw:.3f}s\")"
   ],
   "id": "db89bf413d7eae41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With spell-correction : 0.624s\n",
      "Without correction    : 0.034s\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9e77646545c6c3cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
